
@inproceedings{2010,
  title = {{{TOWARDS A FASTER SYMBOLIC AGGREGATE APPROXIMATION METHOD}}:},
  shorttitle = {{{TOWARDS A FASTER SYMBOLIC AGGREGATE APPROXIMATION METHOD}}},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Software}} and {{Data Technologies}}},
  year = {2010},
  pages = {305--310},
  publisher = {{SciTePress - Science and and Technology Publications}},
  address = {{University of Piraeus, Greece}},
  doi = {10.5220/0003006703050310},
  file = {/home/moritz/Zotero/storage/YGIEBV4P/2010 - TOWARDS A FASTER SYMBOLIC AGGREGATE APPROXIMATION .pdf},
  isbn = {978-989-8425-22-5 978-989-8425-23-2},
  language = {en}
}

@article{aghabozorgi2015,
  title = {Time-Series Clustering \textendash{} {{A}} Decade Review},
  author = {Aghabozorgi, Saeed and Seyed Shirkhorshidi, Ali and Ying Wah, Teh},
  year = {2015},
  month = oct,
  volume = {53},
  pages = {16--38},
  issn = {03064379},
  doi = {10.1016/j.is.2015.04.007},
  abstract = {Clustering is a solution for classifying enormous data when there is not any early knowledge about classes. With emerging new concepts like cloud computing and big data and their vast applications in recent years, research works have been increased on unsupervised solutions like clustering algorithms to extract knowledge from this avalanche of data. Clustering time-series data has been used in diverse scientific areas to discover patterns which empower data analysts to extract valuable information from complex and massive datasets. In case of huge datasets, using supervised classification solutions is almost impossible, while clustering can solve this problem using unsupervised approaches. In this research work, the focus is on time-series data, which is one of the popular data types in clustering problems and is broadly used from gene expression data in biology to stock market analysis in finance. This review will expose four main components of time-series clustering and is aimed to represent an updated investigation on the trend of improvements in efficiency, quality and complexity of clustering time-series approaches during the last decade and enlighten new paths for future works.},
  file = {/home/moritz/Documents/thesis.git/papers/aghabozorgi2015.pdf},
  journal = {Information Systems},
  language = {en}
}

@inproceedings{anacleto2020,
  title = {{{MSAX}}: {{Multivariate Symbolic Aggregate Approximation}} for {{Time Series Classification}}},
  shorttitle = {{{MSAX}}},
  booktitle = {Computational {{Intelligence Methods}} for {{Bioinformatics}} and {{Biostatistics}}},
  author = {Anacleto, Manuel and Vinga, Susana and Carvalho, Alexandra M.},
  editor = {Cazzaniga, Paolo and Besozzi, Daniela and Merelli, Ivan and Manzoni, Luca},
  year = {2020},
  pages = {90--97},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-63061-4_9},
  abstract = {Time Series (TS) analysis is a central research topic in areas such as finance, bioinformatics, and weather forecasting, where the goal is to extract knowledge through data mining techniques. Symbolic aggregate approximation (SAX) is a state-of-the-art method that performs discretization and dimensionality reduction for univariate TS, which are key steps for TS representation and analysis. In this work, we propose MSAX, an extension of this algorithm to multivariate TS that takes into account the covariance structure of the data. The method is tested in several datasets, including the Pen Digits, Character Trajectories, and twelve benchmark files. Depending on the experiment, MSAX exhibits comparable performance with state-of-the-art methods in terms of classification accuracy. Although not superior to 1-nearest neighbor (1-NN) and dynamic time warping (DTW), it has interesting characteristics for some classes, and thus enriches the set of methods to analyze multivariate TS.},
  isbn = {978-3-030-63061-4},
  keywords = {Classification,Multivariate analysis,Symbolic aggregate approximation,Time series},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{ansari2017,
  title = {A {{Review}} of {{Automated Methods}} for {{Detection}} of {{Myocardial Ischemia}} and {{Infarction Using Electrocardiogram}} and {{Electronic Health Records}}},
  author = {Ansari, Sardar and Farzaneh, Negar and Duda, Marlena and Horan, Kelsey and Andersson, Hedvig B. and Goldberger, Zachary D. and Nallamothu, Brahmajee K. and Najarian, Kayvan},
  year = {2017},
  volume = {10},
  pages = {264--298},
  issn = {1937-3333, 1941-1189},
  doi = {10.1109/RBME.2017.2757953},
  file = {/home/moritz/Downloads/IschemiadetectionECG.pdf},
  journal = {IEEE Reviews in Biomedical Engineering},
  language = {en}
}

@article{aremu2019,
  title = {A {{Relative Entropy Weibull}}-{{SAX}} Framework for Health Indices Construction and Health Stage Division in Degradation Modeling of Multivariate Time Series Asset Data},
  author = {Aremu, Oluseun Omotola and {Hyland-Wood}, David and McAree, Peter Ross},
  year = {2019},
  month = apr,
  volume = {40},
  pages = {121--134},
  issn = {1474-0346},
  doi = {10.1016/j.aei.2019.03.003},
  abstract = {Predictive maintenance is the monitoring of an asset's condition over its life cycle to provide a prognosis for when maintenance is required. Prior to prognosis, an asset's life cycle is modeled by a health indicator (HI) which is derived from sensor measurements and describes an asset's degradation over a life cycle. Often an asset's HI is accompanied by a health stage (HS) division, which describes the asset's life cycle condition in discrete states. Generally, HSs are discrete representations generated from discrete state transition models, dynamic state space models, or subjectively defined thresholds, which use sensor measurements to provide a HS division related to an asset's life cycle degradation. HS division methods are often designed for a specific asset in which HS division is based on user assumptions and not generalizable to different asset types or asset data representations. Also, HS division methods are often limited to a bi-state HS division (normal and failure), in which unobservable states are often generalized transition states. As assets become more complex and require multivariate measurements, more advanced methods are required to model an asset's degradation using HIs and HSs. This work introduces Relative Entropy Weibull-SAX (REWS), a data-driven HI and HS degradation modeling method for multivariate asset data. REWS constructs a HI using relative entropy to represent an asset's condition as a change of entropy during its life cycle. The relative entropy representation is then discretized into HS divisions using a Weibull distribution based Symbolic Aggregate approXimation. REWS's utility is demonstrated on the Commercial Modular Aero-Propulsion System Simulation dataset which describes the life cycle observations of multiple aircraft engines.},
  file = {/home/moritz/Zotero/storage/VQIU3N4J/S1474034618305603.html},
  journal = {Advanced Engineering Informatics},
  keywords = {Condition monitoring,Hidden Markov model,Information theory,Kalman filter,Machine learning,Predictive maintenance,Relative entropy,Weibull distribution},
  language = {en}
}

@book{brockwell2016,
  title = {Introduction to {{Time Series}} and {{Forecasting}}},
  author = {Brockwell, Peter J. and Davis, Richard A.},
  year = {2016},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-29854-2},
  file = {/home/moritz/Documents/thesis.git/papers/brockwell2016.pdf},
  isbn = {978-3-319-29852-8 978-3-319-29854-2},
  language = {en},
  series = {Springer {{Texts}} in {{Statistics}}}
}

@article{cerna2000,
  title = {The {{Fundamentals}} of {{FFT}}-{{Based Signal Analysis}} and {{Measurement}}},
  author = {Cerna, Michael and Harvey, Audrey F},
  year = {2000},
  month = jul,
  pages = {20},
  file = {/home/moritz/Zotero/storage/B6HE4A2L/Cerna and Harvey - The Fundamentals of FFT-Based Signal Analysis and .pdf},
  language = {en}
}

@article{das2013,
  title = {Fractional Dynamical Model for the Generation of {{ECG}} like Signals from Filtered Coupled {{Van}}-Der {{Pol}} Oscillators},
  author = {Das, Saptarshi and Maharatna, Koushik},
  year = {2013},
  month = dec,
  volume = {112},
  pages = {490--507},
  issn = {01692607},
  doi = {10.1016/j.cmpb.2013.08.012},
  abstract = {In this paper, an incommensurate fractional order (FO) model has been proposed to generate ECG like waveforms. Earlier investigation of ECG like waveform generation is based on two identical Van-der Pol (VdP) family of oscillators which are coupled by time delays and gains. In this paper, we suitably modify the three state equations corresponding to the nonlinear cross-product of states, time delay coupling of the two oscillators and low-pass filtering, using the concept of fractional derivatives. Our results show that a wide variety of ECG like waveforms can be simulated from the proposed generalized models, characterizing heart conditions under different physiological conditions. Such generalization of the modelling of ECG waveforms may be useful to understand the physiological process behind ECG signal generation in normal and abnormal heart conditions. Along with the proposed FO models, an optimization based approach is also presented to estimate the VdP oscillator parameters for representing a realistic ECG like signal.},
  file = {/home/moritz/Documents/thesis.git/papers/das2013.pdf},
  journal = {Computer Methods and Programs in Biomedicine},
  language = {en},
  number = {3}
}

@article{durham2002,
  title = {Cardiac Arrhythmias: Diagnosis and Management. {{The}} Tachycardias},
  shorttitle = {Cardiac Arrhythmias},
  author = {Durham, D. and Worthley, L. I. G.},
  year = {2002},
  month = mar,
  volume = {4},
  pages = {35--53},
  issn = {1441-2772},
  abstract = {OBJECTIVE: To review the diagnosis and management of cardiac arrhythmias in a two-part presentation. DATA SOURCES: Articles and published peer-review abstracts on tachycardias and bradycardias. SUMMARY OF REVIEW: Normal cardiac rhythm originates from impulses generated within the sinus node. These impulses are conducted to the atrioventricular node where they are delayed before they are distributed to the ventricular myocardium via the His-Purkinje system. Abnormalities in cardiac rhythm are caused by disorders of impulse generation, conduction or a combination of the two and may be life threatening due to a reduction in cardiac output or myocardial oxygenation. Cardiac arrhythmias are commonly classified as tachycardias (supraventricular or ventricular) or bradycardias. The differentiation between supraventricular and ventricular tachycardias usually requires an assessment of atrial and ventricular rhythms and their relationship to each other. In the critically ill patient the commonest tachycardia is sinus tachycardia and treatment generally consist of management of the underlying disorder. Other supraventricular tachycardias (SVTs) include, atrial flutter, atrial fibrillation and paroxysmal supraventricular tachycardia (PSVT) all of which may require cardioversion, although to maintain sinus rhythm, antiarrhythmic therapy is often needed. Adenosine is useful in management and treatment many SVTs although its use in PSVT with Wolff-Parkinson-White syndrome is hazardous. Multifocal atrial tachycardia is a characteristic supraventricular tachycardia found in the critical ill patient. While it usually responds to intravenous magnesium sulphate, its management also requires removal of various precipitating factors. Ventricular tachycardia (VT) and ventricular fibrillation (VF) require urgent cardioversion and defibrillation respectively. Torsade de pointes should be differentiated from these ventricular arrhythmias as antiarrhythmic therapy may be contraindicated. CONCLUSIONS: Supraventricular and ventricular tachycardias in the critically ill patient often have underlying disorders that precipitate their development (e.g. hypokalaemia, hypomagnesaemia, anti-arrhythmic proarrhythmia, myocardial ischaemia, etc). While antiarrhythmic therapy and cardioversion or defibrillation may be required to achieve sinus rhythm, correction of the associated abnormalities is also required.},
  journal = {Critical Care and Resuscitation: Journal of the Australasian Academy of Critical Care Medicine},
  language = {eng},
  number = {1},
  pmid = {16573402}
}

@inproceedings{esmael2012,
  title = {Multivariate {{Time Series Classification}} by {{Combining Trend}}-{{Based}} and {{Value}}-{{Based Approximations}}},
  booktitle = {Computational {{Science}} and {{Its Applications}} \textendash{} {{ICCSA}} 2012},
  author = {Esmael, Bilal and Arnaout, Arghad and Fruhwirth, Rudolf K. and Thonhauser, Gerhard},
  editor = {Murgante, Beniamino and Gervasi, Osvaldo and Misra, Sanjay and Nedjah, Nadia and Rocha, Ana Maria A. C. and Taniar, David and Apduhan, Bernady O.},
  year = {2012},
  pages = {392--403},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-31128-4_29},
  abstract = {Multivariate time series data often have a very high dimensionality. Classifying such high dimensional data poses a challenge because a vast number of features can be extracted. Furthermore, the meaning of the normally intuitive term ``similar to'' needs to be precisely defined. Representing the time series data effectively is an essential task for decision-making activities such as prediction, clustering and classification. In this paper we propose a feature-based classification approach to classify real-world multivariate time series generated by drilling rig sensors in the oil and gas industry. Our approach encompasses two main phases: representation and classification.For the representation phase, we propose a novel representation of time series which combines trend-based and value-based approximations (we abbreviate it as TVA). It produces a compact representation of the time series which consists of symbolic strings that represent the trends and the values of each variable in the series. The TVA representation improves both the accuracy and the running time of the classification process by extracting a set of informative features suitable for common classifiers.For the classification phase, we propose a memory-based classifier which takes into account the antecedent results of the classification process. The inputs of the proposed classifier are the TVA features computed from the current segment, as well as the predicted class of the previous segment.Our experimental results on real-world multivariate time series show that our approach enables highly accurate and fast classification of multivariate time series.},
  isbn = {978-3-642-31128-4},
  keywords = {Event Detection,Symbolic Aggregate Approximation,Time Series Classification,Time Series Representation},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@book{guigou2017,
  title = {Anomaly Detection and Motif Discovery in Symbolic Representations of Time Series},
  author = {Guigou, Fabio and Collet, Pierre and Parrend, Pierre},
  year = {2017},
  month = apr,
  doi = {10.13140/RG.2.2.20158.69447},
  abstract = {The advent of the Big Data hype and the consistent recollection of event logs and real-time data from sensors, monitoring software and machine configuration has generated a huge amount of time-varying data in about every sector of the industry. Rule-based processing of such data has ceased to be relevant in many scenarios where anomaly detection and pattern mining have to be entirely accomplished by the machine. Since the early 2000s, the de-facto standard for representing time series has been the Symbolic Aggregate approXimation (SAX). In this document, we present a few algorithms using this representation for anomaly detection and motif discovery, also known as pattern mining, in such data. We propose a benchmark of anomaly detection algorithms using data from Cloud monitoring software.},
  file = {/home/moritz/Zotero/storage/Y3ML5C2Q/Guigou et al. - 2017 - Anomaly detection and motif discovery in symbolic .pdf},
  keywords = {Anomaly detection,Pattern mining,Symbolic representation,Time series}
}

@article{he2020,
  title = {A {{Boundary Distance}}-{{Based Symbolic Aggregate Approximation Method}} for {{Time Series Data}}},
  author = {He, Zhenwen and Long, Shirong and Ma, Xiaogang and Zhao, Hong},
  year = {2020},
  month = nov,
  volume = {13},
  pages = {284},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/a13110284},
  abstract = {A large amount of time series data is being generated every day in a wide range of sensor application domains. The symbolic aggregate approximation (SAX) is a well-known time series representation method, which has a lower bound to Euclidean distance and may discretize continuous time series. SAX has been widely used for applications in various domains, such as mobile data management, financial investment, and shape discovery. However, the SAX representation has a limitation: Symbols are mapped from the average values of segments, but SAX does not consider the boundary distance in the segments. Different segments with similar average values may be mapped to the same symbols, and the SAX distance between them is 0. In this paper, we propose a novel representation named SAX-BD (boundary distance) by integrating the SAX distance with a weighted boundary distance. The experimental results show that SAX-BD significantly outperforms the SAX representation, ESAX representation, and SAX-TD representation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/moritz/Zotero/storage/RW3YL2HA/He et al. - 2020 - A Boundary Distance-Based Symbolic Aggregate Appro.pdf;/home/moritz/Zotero/storage/YFDBPPRM/284.html},
  journal = {Algorithms},
  keywords = {ESAX,SAX,SAX-BD,SAX-TD,time series},
  language = {en},
  number = {11}
}

@inproceedings{hughes2003,
  title = {Markov {{Models}} for {{Automated ECG Interval Analysis}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 16 [{{Neural Information Systems}}, \{\vphantom\}{{NIPS}}\vphantom\{\} 2003, {{December}} 8-13, 2003, {{Vancouver}} and {{Whistler}}, {{British Columbia}}, {{Canada}}]},
  author = {Hughes, Nicholas P and Tarassenko, Lionel and Roberts, Stephen J},
  year = {2003},
  pages = {611--618},
  publisher = {{MIT Press}},
  address = {{Vancouver Whistler, British Columbia, Canada}},
  url = {https://proceedings.neurips.cc/paper/2003/hash/b23975176653284f1f7356ba5539cfcb-Abstract.html},
  abstract = {We examine the use of hidden Markov and hidden semi-Markov models for automatically segmenting an electrocardiogram waveform into its constituent waveform features. An undecimated wavelet transform is used to generate an overcomplete representation of the signal that is more appropriate for subsequent modelling. We show that the state durations implicit in a standard hidden Markov model are ill-suited to those of real ECG features, and we investigate the use of hidden semi-Markov models for improved state duration modelling.},
  file = {/home/moritz/Documents/thesis.git/papers/hughes2003.pdf},
  language = {en}
}

@article{ieva2013a,
  title = {Multivariate Functional Clustering for the Morphological Analysis of Electrocardiograph Curves},
  author = {Ieva, Francesca and Paganoni, Anna M. and Pigoli, Davide and Vitelli, Valeria},
  year = {2013},
  volume = {62},
  pages = {401--418},
  publisher = {{[Wiley, Royal Statistical Society]}},
  issn = {0035-9254},
  url = {https://www.jstor.org/stable/24771812},
  urldate = {2021-03-30},
  abstract = {Cardiovascular ischaemic diseases are one of the main causes of death all over the world. In this class of pathologies, a quick diagnosis is essential for a good prognosis in reperfusive treatment. In particular, an automatic classification procedure based on statistical analysis of teletransmitted electrocardiograph ('ECG') traces would be very helpful for an early diagnosis. This work presents an analysis of ECG traces, either physiological or pathological, of patients whose 12-lead prehospital ECG has been sent to the 118 Dispatch Center in Milan by life-support personnel. The statistical analysis starts with a preprocessing step, where functional data are reconstructed from noisy observations and biological variability is removed by a non-linear registration procedure. Then, a multivariate functional k-means clustering procedure is carried out on reconstructed and registered ECGs and their first derivatives. Hence, a new semi-automatic diagnostic procedure, based solely on the ECG morphology, is proposed to classify ECG traces; finally, the performance of this classification method is evaluated.},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {3}
}

@inproceedings{javed2014,
  title = {An Adaptive Noise Cancelation Model for Removal of Noise from Modeled {{ECG}} Signals},
  booktitle = {2014 {{IEEE REGION}} 10 {{SYMPOSIUM}}},
  author = {Javed, Shazia and Ahmad, Noor Atinah},
  year = {2014},
  month = apr,
  pages = {471--475},
  publisher = {{IEEE}},
  address = {{Kuala Lumpur, Malaysia}},
  doi = {10.1109/TENCONSpring.2014.6863079},
  abstract = {In this paper an adaptive noise cancelation (ANC) model is presented to remove baseline wander (BW) noise from mathematically modeled ECG signals. The ANC model is designed to have a trade-off between the correlation properties of noise and reference signals. Matlab is used to simulate ECG signals artificially, to represent different sinus rhythms and leads of ECG waveform. Furthermore contamination of an important artifact (baseline wander) is simulated for normal ECG lead II, and then identified using LMS algorithm and its preconditioned versions: NLMS and TDLMS algorithms, to get denoised ECG signals. Experimental results are presented for a comparison of these adaptive algorithm, which shows preference of TDLMS algorithm over the rest.},
  file = {/home/moritz/Documents/thesis.git/papers/javed2014.pdf},
  isbn = {978-1-4799-2027-3 978-1-4799-2028-0},
  language = {en}
}

@incollection{javed2019,
  ids = {javed2019a,javed2019b},
  title = {Mathematical {{Modeling}} of {{Real Time ECG Waveform}}},
  booktitle = {Intelligent {{Computing}}},
  author = {Javed, Shazia and Ahmad, Noor Atinah},
  editor = {Arai, Kohei and Kapoor, Supriya and Bhatia, Rahul},
  year = {2019},
  volume = {858},
  pages = {606--614},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-01174-1_46},
  abstract = {Electrocardiogram (ECG) is a digital recording of heart rate variability that is used to detect the cardiac disorders. Often these recordings are affected by physiological and instrumental noises that affects an accurate diagnosis of the disease. An exact understanding of ECG waveform may help in overcoming such issues. Mathematical modeling is efficiently used to understand the pattern of 12-lead ECG and simulate real time ECG's waveform. Real ECG can be taken as a superposition of bounded functions and this property is a defining feature of almost periodic functions (APF). The proposed model has utilized this characteristic of ECG signals to generate the real time ECG waveform with negligibly small error.},
  file = {/home/moritz/Documents/thesis.git/papers/javed2019.pdf},
  isbn = {978-3-030-01173-4 978-3-030-01174-1},
  language = {en}
}

@article{kanani2020,
  title = {{{ECG Heartbeat Arrhythmia Classification Using Time}}-{{Series Augmented Signals}} and {{Deep Learning Approach}}},
  author = {Kanani, Pratik and Padole, Mamta},
  year = {2020},
  month = jan,
  volume = {171},
  pages = {524--531},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2020.04.056},
  abstract = {Electrocardiogram (ECG) signals are the best way to monitor the functionality and health of the cardiovascular system and also identify ailments related to it. Abnormal heartbeats are reflected in the ECG pattern and such abnormal signals are called as Arrhythmias. Automated classification and identification of the ECG arrhythmia signal that provides faster and more accurate result is increasingly becoming the need of the moment. Various machine learning skills have been applied to advance the accuracy of results and increase the speed and robustness of the models. A lot of focus has been given to the architectures and datasets employed but preprocessing of the data being equally important. In this paper, a preprocessing technique that significantly improves the accuracy of the deep learning models used for ECG classification is proposed with a modified deep learning architecture that adds to the training stability. With this preprocessing technique and deep learning model, the system is able to attain accuracy levels of more than 99\% without overfitting the model.},
  file = {/home/moritz/Zotero/storage/6QYQYM9L/Kanani and Padole - 2020 - ECG Heartbeat Arrhythmia Classification Using Time.pdf},
  journal = {Procedia Computer Science},
  keywords = {accuracy,Arrhythmias,Augmentation,Deep Learning,ECG,Optimizer,stability,transformations},
  language = {en},
  series = {Third {{International Conference}} on {{Computing}} and {{Network Communications}} ({{CoCoNet}}'19)}
}

@article{kaur2016,
  ids = {kaur2016a},
  title = {{{ECG Signal Analysis}} and {{Arrhythmia Detection}} Using {{Wavelet Transform}}},
  author = {Kaur, Inderbir and Rajni, Rajni and Marwaha, Anupma},
  year = {2016},
  month = dec,
  volume = {97},
  pages = {499--507},
  issn = {2250-2106, 2250-2114},
  doi = {10.1007/s40031-016-0247-3},
  abstract = {Electrocardiogram (ECG) is used to record the electrical activity of the heart. The ECG signal being nonstationary in nature, makes the analysis and interpretation of the signal very difficult. Hence accurate analysis of ECG signal with a powerful tool like discrete wavelet transform (DWT) becomes imperative. In this paper, ECG signal is denoised to remove the artifacts and analyzed using Wavelet Transform to detect the QRS complex and arrhythmia. This work is implemented in MATLAB software for MIT/BIH Arrhythmia database and yields the sensitivity of 99.85 \%, positive predictivity of 99.92 \% and detection error rate of 0.221 \% with wavelet transform. It is also inferred that DWT outperforms principle component analysis technique in detection of ECG signal.},
  file = {/home/moritz/Documents/thesis.git/papers/kaur2016.pdf},
  journal = {Journal of The Institution of Engineers (India): Series B},
  language = {en},
  number = {4}
}

@article{keogh,
  title = {On the {{Need}} for {{Time Series Data Mining Benchmarks}}: {{A Survey}} and {{Empirical Demonstration}}},
  author = {Keogh, Eamonn and Kasetty, Shruti},
  pages = {10},
  abstract = {In the last decade there has been an explosion of interest in mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made (speed in'the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of "improvement" that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2002.pdf},
  language = {en}
}

@inproceedings{keogh2005,
  title = {{{HOT SAX}}: {{Efficiently Finding}} the {{Most Unusual Time Series Subsequence}}},
  shorttitle = {{{HOT SAX}}},
  booktitle = {Fifth {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}}'05)},
  author = {Keogh, E. and Lin, J. and Fu, A.},
  year = {2005},
  pages = {226--233},
  publisher = {{IEEE}},
  address = {{Houston, TX, USA}},
  doi = {10.1109/ICDM.2005.79},
  abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. As we will show, discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2005.pdf},
  isbn = {978-0-7695-2278-4},
  language = {en}
}

@article{keogh2006,
  title = {Finding the Most Unusual Time Series Subsequence: Algorithms and Applications},
  shorttitle = {Finding the Most Unusual Time Series Subsequence},
  author = {Keogh, Eamonn and Lin, Jessica and Lee, Sang-Hee and Herle, Helga Van},
  year = {2006},
  month = dec,
  volume = {11},
  pages = {1--27},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-006-0034-6},
  abstract = {In this work we introduce the new problem of finding time series discords. Time series discords are subsequences of longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. While discords have many uses for data mining, they are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. While the brute force algorithm to discover time series discords is quadratic in the length of the time series, we show a simple algorithm that is three to four orders of magnitude faster than brute force, while guaranteed to produce identical results. We evaluate our work with a comprehensive set of experiments on diverse data sources including electrocardiograms, space telemetry, respiration physiology, anthropological and video datasets.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2006a.pdf},
  journal = {Knowledge and Information Systems},
  language = {en},
  number = {1}
}

@article{keogh2006a,
  title = {Finding {{Unusual Medical Time}}-{{Series Subsequences}}: {{Algorithms}} and {{Applications}}},
  shorttitle = {Finding {{Unusual Medical Time}}-{{Series Subsequences}}},
  author = {Keogh, E. and Lin, J. and Fu, A.W. and Van Herle, H.},
  year = {2006},
  month = jul,
  volume = {10},
  pages = {429--439},
  issn = {1089-7771, 1558-0032},
  doi = {10.1109/TITB.2005.863870},
  abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. While discords have many uses for data mining, they are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence), unlike most anomaly detection algorithms that typically require many parameters. While the brute force algorithm to discover time series discords is quadratic in the length of the time series, we show a simple algorithm that is three to four orders of magnitude faster than brute force, while guaranteed to produce identical results. We evaluate our work with a comprehensive set of experiments on electrocardiograms and other medical datasets.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2006.pdf},
  journal = {IEEE Transactions on Information Technology in Biomedicine},
  language = {en},
  number = {3}
}

@article{kulahcioglu2021,
  title = {Application of {{Symbolic Piecewise Aggregate Approximation}} ({{PAA}}) {{Analysis}} to {{ECG Signals}}},
  author = {Kulahcioglu, Burcu and Ozdemir, Serhan and Kumova, Bora},
  year = {2021},
  month = mar,
  abstract = {Symbolic Time Series Analysis (STA) is an emerging methodology that involves coarse graining of the signals. Repeating segments of the time series are associated with symbols, thereby reducing the complexity of the series. It facilitates data mining tasks to be performed easily such as indexing, clustering, classification, summarization, and anomaly detection. This study involves symbolization through Symbolic Aggregate Approximation (SAX) with Piecewise Aggregate Approximation (PAA). The same ECG series is symbolized first by PLA and then PAA. Coarsing the series by PLA proved to be more problematic than PAA. At coarser scales, details are lost in noise with PLA, whereas local features become clearer with PAA. However during the analyses of ECGs of various subjects, it is understood that PAA fails when the series is not perfectly periodic as in rotating machinery. This fact is contrasted with the synthetic ECG which is manipulated to be perfectly periodic to juxtapose the results of the two trials. It is deduced that PAA delivers better pattern detection when signals are truly periodic.}
}

@inproceedings{lin2003,
  title = {A Symbolic Representation of Time Series, with Implications for Streaming Algorithms},
  booktitle = {Proceedings of the 8th {{ACM SIGMOD}} Workshop on {{Research}} Issues in Data Mining and Knowledge Discovery  - {{DMKD}} '03},
  author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill},
  year = {2003},
  pages = {2--11},
  publisher = {{ACM Press}},
  address = {{San Diego, California}},
  doi = {10.1145/882082.882086},
  abstract = {The parallel explosions of interest in streaming data, and data mining of time series have had surprisingly little intersection. This is in spite of the fact that time series data are typically streaming data. The main reason for this apparent paradox is the fact that the vast majority of work on streaming data explicitly assumes that the data is discrete, whereas the vast majority of time series data is real valued.Many researchers have also considered transforming real valued time series into symbolic representations, nothing that such representations would potentially allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities, in addition to allowing formerly "batch-only" problems to be tackled by the streaming community. While many symbolic representations of time series have been introduced over the past decades, they all suffer from three fatal flaws. Firstly, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Secondly, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. Finally, most of these symbolic approaches require one to have access to all the data, before creating the symbolic representation. This last feature explicitly thwarts efforts to use the representations with streaming algorithms.In this work we introduce a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. Finally, our representation allows the real valued data to be converted in a streaming fashion, with only an infinitesimal time and space overhead.We will demonstrate the utility of our representation on the classic data mining tasks of clustering, classification, query by content and anomaly detection.},
  file = {/home/moritz/Documents/thesis.git/papers/lin2003.pdf},
  language = {en}
}

@inproceedings{liu2018,
  title = {Classification of {{Heart Diseases Based On ECG Signals Using Long Short}}-{{Term Memory}}},
  booktitle = {2018 40th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  author = {Liu, M. and Kim, Y.},
  year = {2018},
  month = jul,
  pages = {2707--2710},
  issn = {1558-4615},
  doi = {10.1109/EMBC.2018.8512761},
  abstract = {Heart disease classification based on electrocardiogram(ECG) signal has become a priority topic in the diagnosis of heart diseases because it can be obtained with a simple diagnostic tool of low cost. Since early detection of heart disease can enable us to ease the treatment as well as save people's lives, accurate detection of heart disease using ECG is very important. In this paper, we propose a classification method of heart diseases based on ECG by adopting a machine learning method, called Long Short-Term Memory (LSTM), which is a state-of-the-art technique analyzing time series sequences in deep learning. As suitable data preprocessing, we also utilize symbolic aggregate approximation (SAX) to improve the accuracy. Our experiment results show that our approach not only achieves significantly better accuracy but also classifies heart diseases correctly in smaller response time than baseline techniques.},
  file = {/home/moritz/Zotero/storage/T6BYWC76/8512761.html},
  keywords = {Data preprocessing,deep learning,Deep Learning,diseases,Diseases,electrocardiogram signal,electrocardiography,Electrocardiography,Feature extraction,Heart,heart disease classification,Heart Diseases,Humans,learning (artificial intelligence),Long Short-Term Memory,machine learning method,medical signal processing,signal classification,state-of-the-art technique,symbolic aggregate approximation,Time factors,time series,time series sequences,Transforms}
}

@inproceedings{lkhagva2006,
  title = {Extended {{SAX}}: {{Extension}} of {{Symbolic Aggregate Approximation}} for {{Financial Time Series Data Representation}}},
  booktitle = {Proceeding of {{IEICE}} the 17th {{Data Engineering Workshop}}},
  author = {Lkhagva, Battuguldur and Suzuki, Yu and Kawagoe, Kyoji},
  year = {2006},
  pages = {7},
  address = {{Ginowan, Japan}},
  url = {https://www.researchgate.net/publication/229046404_Extended_SAX_extension_of_symbolic_aggregate_approximation_for_financial_time_series_data_representation},
  urldate = {2021-02-27},
  abstract = {Efficient and accurate similarity searching for a large amount of time series data set is an important but non-trivial problem. Many dimensionality reduction techniques have been proposed for effective representation of time series data in order to realize such similarity searching, including Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), the Adaptive Piecewise Constant Approximation (APCA), and the recently proposed Symbolic Aggregate Approximation (SAX).},
  file = {/home/moritz/Documents/thesis.git/papers/lkhagva2006.pdf},
  language = {en}
}

@inproceedings{malinowski2013,
  title = {1d-{{SAX}}: {{A Novel Symbolic Representation}} for {{Time Series}}},
  shorttitle = {1d-{{SAX}}},
  booktitle = {Advances in {{Intelligent Data Analysis XII}}},
  author = {Malinowski, Simon and Guyet, Thomas and Quiniou, Ren{\'e} and Tavenard, Romain},
  editor = {Tucker, Allan and H{\"o}ppner, Frank and Siebes, Arno and Swift, Stephen},
  year = {2013},
  pages = {273--284},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-41398-8_24},
  abstract = {SAX (Symbolic Aggregate approXimation) is one of the main symbolization techniques for time series. A well-known limitation of SAX is that trends are not taken into account in the symbolization. This paper proposes 1d-SAX a method to represent a time series as a sequence of symbols that each contain information about the average and the trend of the series on a segment. We compare the efficiency of SAX and 1d-SAX in terms of goodness-of-fit, retrieval and classification performance for querying a time series database with an asymmetric scheme. The results show that 1d-SAX improves performance using equal quantity of information, especially when the compression rate increases.},
  file = {/home/moritz/Zotero/storage/EQB5BMS4/Malinowski et al. - 2013 - 1d-SAX A Novel Symbolic Representation for Time S.pdf},
  isbn = {978-3-642-41398-8},
  keywords = {Average Approximation Error,Dynamic Time Warping Distance,Original Time Series,Symbolic Representation,Time Series},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@inproceedings{maniewski1997,
  ids = {maniewski1997a},
  title = {Time-Frequency Methods for High-Resolution {{ECG}} Analysis},
  booktitle = {Proceedings of 18th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}},
  author = {Maniewski, R. and Lewandowski, P. and Nowinska, M. and Mroczka, T.},
  year = {1997},
  volume = {3},
  pages = {1266--1267},
  publisher = {{IEEE}},
  address = {{Amsterdam, Netherlands}},
  doi = {10.1109/IEMBS.1996.652804},
  file = {/home/moritz/Documents/thesis.git/papers/maniewski1997.pdf},
  isbn = {978-0-7803-3811-1},
  keywords = {comparison,ecg,overview},
  language = {en}
}

@article{moskovitch2015,
  title = {Classification of Multivariate Time Series via Temporal Abstraction and Time Intervals Mining},
  author = {Moskovitch, Robert and Shahar, Yuval},
  year = {2015},
  month = oct,
  volume = {45},
  pages = {35--74},
  issn = {0219-3116},
  doi = {10.1007/s10115-014-0784-5},
  abstract = {Classification of multivariate time series data, often including both time points and intervals at variable frequencies, is a challenging task. We introduce the KarmaLegoSification (KLS) framework for classification of multivariate time series analysis, which implements three phases: (1) application of a temporal abstraction process that transforms a series of raw time-stamped data points into a series of symbolic time intervals; (2) mining these symbolic time intervals to discover frequent time-interval-related patterns (TIRPs), using Allen's temporal relations; and (3) using the TIRPs as features to induce a classifier. To efficiently detect multiple TIRPs (features) in a single entity to be classified, we introduce a new algorithm, SingleKarmaLego, which can be shown to be superior for that purpose over a Sequential TIRPs Detection algorithm. We evaluated the KLS framework on datasets in the domains of diabetes, intensive care, and infectious hepatitis, assessing the effects of the various settings of the KLS framework. Discretization using Symbolic Aggregate approXimation (SAX) led to better performance than using the equal-width discretization (EWD); knowledge-based cut-off definitions when available were superior to both. Using three abstract temporal relations was superior to using the seven core temporal relations. Using an epsilon value larger than zero tended to result in a slightly better accuracy when using the SAX discretization method, but resulted in a reduced accuracy when using EWD, and overall, does not seem beneficial. No feature selection method we tried proved useful. Regarding feature (TIRP) representation, mean duration performed better than horizontal support, which in turn performed better than the default Binary (existence) representation method.},
  file = {/home/moritz/Zotero/storage/TMPYEWGA/Moskovitch and Shahar - 2015 - Classification of multivariate time series via tem.pdf},
  journal = {Knowledge and Information Systems},
  language = {en},
  number = {1}
}

@article{ordonez2008,
  title = {Visualizing {{Multivariate Time Series Data}} to {{Detect Specific Medical Conditions}}},
  author = {Ord{\'o}{\~n}ez, Patricia and {desJardins}, Marie and Feltes, Carolyn and Lehmann, Christoph U. and Fackler, James},
  year = {2008},
  volume = {2008},
  pages = {530--534},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2656052/},
  urldate = {2021-03-30},
  abstract = {Efficient unsupervised algorithms for the detection of patterns in time series data, often called motifs, have been used in many applications, such as identifying words in different languages, detecting anomalies in ECG readings, and finding similarities between images. We present a process that creates a personalized multivariate time series representation\textemdash a Multivariate Time Series Amalgam (MTSA) \textemdash{} of physiological data and laboratory results that physicians can visually interpret. We then apply a technique that has demonstrated success with the interpretation of univariate data, named Symbolic Aggregate Approximation (SAX), to visualize patterns in the MTSAs that may differentiate between medical conditions such as renal and respiratory failure.},
  file = {/home/moritz/Zotero/storage/MQFAWGBC/Ordóñez et al. - 2008 - Visualizing Multivariate Time Series Data to Detec.pdf},
  journal = {AMIA Annual Symposium Proceedings},
  pmcid = {PMC2656052},
  pmid = {18999033}
}

@article{park2020,
  title = {{{SAX}}-{{ARM}}: {{Deviant}} Event Pattern Discovery from Multivariate Time Series Using Symbolic Aggregate Approximation and Association Rule Mining},
  shorttitle = {{{SAX}}-{{ARM}}},
  author = {Park, Hoonseok and Jung, Jae-Yoon},
  year = {2020},
  month = mar,
  volume = {141},
  pages = {112950},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2019.112950},
  abstract = {The discovery of event patterns from multivariate time series is important to academics and practitioners. In particular, we consider the event patterns related to anomalies such as outliers and deviations, which are important factors in system monitoring for manufacturing processes. In this paper, we propose a method for discovering the rules to describe deviant event patterns from multivariate time series, called SAX-ARM (association rule mining based on symbolic aggregate approximation). Inverse normal transformation (INT) is first adopted for converting the distribution of time series to the normal distribution. Then, symbolic aggregate approximation (SAX) is applied to symbolize time series, and association rule mining (ARM) is used for discovering frequent rules among the symbols of deviant events. The experimental results show the discovery of informative rules among deviant events in a multivariate time series from a die-casting manufacturing process that has ten variables with 1,437 lengths. We also present the results of sensitivity analysis, which demonstrates that significant rules can be discovered with different settings of the SAX parameters. The results describe the usefulness of the proposed method to identify deviant event among multivariate time series with high complexity.},
  file = {/home/moritz/Zotero/storage/W473NEMY/S0957417419306682.html},
  journal = {Expert Systems with Applications},
  keywords = {Association rule mining (ARM),Event pattern discovery,Inverse normal transformation (INT),Multivariate time series,Symbolic aggregate approximation (SAX)},
  language = {en}
}

@inproceedings{pham2010,
  title = {{{HOT aSAX}}: {{A Novel Adaptive Symbolic Representation}} for {{Time Series Discords Discovery}}},
  shorttitle = {{{HOT aSAX}}},
  booktitle = {Intelligent {{Information}} and {{Database Systems}}},
  author = {Pham, Ninh D. and Le, Quang Loc and Dang, Tran Khanh},
  editor = {Nguyen, Ngoc Thanh and Le, Manh Thanh and {\'S}wi{\k{a}}tek, Jerzy},
  year = {2010},
  pages = {113--121},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-12145-6_12},
  abstract = {Finding discords in time series database is an important problem in the last decade due to its variety of real-world applications, including data cleansing, fault diagnostics, and financial data analysis. The best known approach to our knowledge is HOT SAX technique based on the equiprobable distribution of SAX representations of time series. This characteristic, however, is not preserved in the reduced-dimensionality literature, especially on the lack of Gaussian distribution datasets. In this paper, we introduce a k-means based algorithm for symbolic representations of time series called adaptive Symbolic Aggregate approXimation (aSAX) and propose HOT aSAX algorithm for time series discords discovery. Due to the clustered characteristic of aSAX words, our algorithm produces greater pruning power than the previous approach. Our empirical experiments with real-world time series datasets confirm the theoretical analyses as well as the efficiency of our approach.},
  file = {/home/moritz/Zotero/storage/8C8W37CT/Pham et al. - 2010 - HOT aSAX A Novel Adaptive Symbolic Representation.pdf},
  isbn = {978-3-642-12145-6},
  keywords = {Anomaly Detection,Clustering,SAX,Time Series Data Mining},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{sivaraks2015,
  title = {Robust and {{Accurate Anomaly Detection}} in {{ECG Artifacts Using Time Series Motif Discovery}}},
  author = {Sivaraks, Haemwaan and Ratanamahatana, Chotirat Ann},
  year = {2015},
  month = jan,
  volume = {2015},
  pages = {e453214},
  publisher = {{Hindawi}},
  issn = {1748-670X},
  doi = {10.1155/2015/453214},
  abstract = {Electrocardiogram (ECG) anomaly detection is an important technique for detecting dissimilar heartbeats which helps identify abnormal ECGs before the diagnosis process. Currently available ECG anomaly detection methods, ranging from academic research to commercial ECG machines, still suffer from a high false alarm rate because these methods are not able to differentiate ECG artifacts from real ECG signal, especially, in ECG artifacts that are similar to ECG signals in terms of shape and/or frequency. The problem leads to high vigilance for physicians and misinterpretation risk for nonspecialists. Therefore, this work proposes a novel anomaly detection technique that is highly robust and accurate in the presence of ECG artifacts which can effectively reduce the false alarm rate. Expert knowledge from cardiologists and motif discovery technique is utilized in our design. In addition, every step of the algorithm conforms to the interpretation of cardiologists. Our method can be utilized to both single-lead ECGs and multilead ECGs. Our experiment results on real ECG datasets are interpreted and evaluated by cardiologists. Our proposed algorithm can mostly achieve 100\% of accuracy on detection (AoD), sensitivity, specificity, and positive predictive value with 0\% false alarm rate. The results demonstrate that our proposed method is highly accurate and robust to artifacts, compared with competitive anomaly detection methods.},
  file = {/home/moritz/Zotero/storage/49RUWZFN/Sivaraks and Ratanamahatana - 2015 - Robust and Accurate Anomaly Detection in ECG Artif.pdf},
  journal = {Computational and Mathematical Methods in Medicine},
  language = {en}
}

@article{song2020a,
  title = {Transitional {{SAX Representation}} for {{Knowledge Discovery}} for {{Time Series}}},
  author = {Song, Kiburm and Ryu, Minho and Lee, Kichun},
  year = {2020},
  month = oct,
  volume = {10},
  pages = {6980},
  issn = {2076-3417},
  doi = {10.3390/app10196980},
  abstract = {Numerous dimensionality-reducing representations of time series have been proposed in data mining and have proved to be useful, especially in handling a high volume of time series data. Among them, widely used symbolic representations such as symbolic aggregate approximation and piecewise aggregate approximation focus on information of local averages of time series. To compensate for such methods, several attempts were made to include trend information. However, the included trend information is quite simple, leading to great information loss. Such information is hardly extendable, so adjusting the level of simplicity to a higher complexity is difficult. In this paper, we propose a new symbolic representation method called transitional symbolic aggregate approximation that incorporates transitional information into symbolic aggregate approximations. We show that the proposed method, satisfying a lower bound of the Euclidean distance, is able to preserve meaningful information, including dynamic trend transitions in segmented time series, while still reducing dimensionality. We also show that this method is advantageous from theoretical aspects of interpretability, and practical and superior in terms of time-series classification tasks when compared with existing symbolic representation methods.},
  file = {C\:\\Users\\morit\\Downloads\\applsci-10-06980-v3 (1).pdf},
  journal = {Applied Sciences},
  language = {en},
  number = {19}
}

@article{sun2014,
  ids = {sun2014a},
  title = {An Improvement of Symbolic Aggregate Approximation Distance Measure for Time Series},
  author = {Sun, Youqiang and Li, Jiuyong and Liu, Jixue and Sun, Bingyu and Chow, Christopher},
  year = {2014},
  month = aug,
  volume = {138},
  pages = {189--198},
  issn = {09252312},
  doi = {10.1016/j.neucom.2014.01.045},
  abstract = {Symbolic Aggregate approXimation (SAX) as a major symbolic representation has been widely used in many time series data mining applications. However, because a symbol is mapped from the average value of a segment, the SAX ignores important information in a segment, namely the trend of the value change in the segment. Such a miss may cause a wrong classification in some cases, since the SAX representation cannot distinguish different time series with similar average values but different trends. In this paper, we firstly design a measure to compute the distance of trends using the starting and the ending points of segments. Then we propose a modified distance measure by integrating the SAX distance with a weighted trend distance. We show that our distance measure has a tighter lower bound to the Euclidean distance than that of the original SAX. The experimental results on diverse time series data sets demonstrate that our proposed representation significantly outperforms the original SAX representation and an improved SAX representation for classification.},
  file = {/home/moritz/Documents/thesis.git/papers/sun2014.pdf;/home/moritz/Zotero/storage/9UUDIKCJ/S0925231214002872.html},
  journal = {Neurocomputing},
  keywords = {Classification,Lower bound,Symbolic Aggregate approXimation,Time series,Trend distance},
  language = {en}
}

@article{sun2014a,
  title = {An Improvement of Symbolic Aggregate Approximation Distance Measure for Time Series},
  author = {Sun, Youqiang and Li, Jiuyong and Liu, Jixue and Sun, Bingyu and Chow, Christopher},
  year = {2014},
  month = aug,
  volume = {138},
  pages = {189--198},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2014.01.045},
  abstract = {Symbolic Aggregate approXimation (SAX) as a major symbolic representation has been widely used in many time series data mining applications. However, because a symbol is mapped from the average value of a segment, the SAX ignores important information in a segment, namely the trend of the value change in the segment. Such a miss may cause a wrong classification in some cases, since the SAX representation cannot distinguish different time series with similar average values but different trends. In this paper, we firstly design a measure to compute the distance of trends using the starting and the ending points of segments. Then we propose a modified distance measure by integrating the SAX distance with a weighted trend distance. We show that our distance measure has a tighter lower bound to the Euclidean distance than that of the original SAX. The experimental results on diverse time series data sets demonstrate that our proposed representation significantly outperforms the original SAX representation and an improved SAX representation for classification.},
  journal = {Neurocomputing},
  keywords = {Classification,Lower bound,Symbolic Aggregate approXimation,Time series,Trend distance},
  language = {en}
}

@inproceedings{tamura2017,
  title = {Clustering of Time Series Using Hybrid Symbolic Aggregate Approximation},
  booktitle = {2017 {{IEEE Symposium Series}} on {{Computational Intelligence}} ({{SSCI}})},
  author = {Tamura, K. and Ichimura, T.},
  year = {2017},
  month = nov,
  pages = {1--8},
  doi = {10.1109/SSCI.2017.8280846},
  abstract = {Clustering of time series is one of the best-known grand challenges in time series analysis because of its application potentialities and difficulty. It is like data clustering and the task of partitioning time series into several groups based on their similarities, such that time series in a cluster are similar and they are not similar to other clusters. In the last decade, symbolic aggregate approximation (SAX), which is a high-level symbolic representation for time series, has attracted the attention of many data mining researchers. SAX enables time series analysis to be applied to sequence mining techniques. In this study, we propose a new approach for clustering time series that utilizes a moving average convergence divergence (MACD)-histogram-based SAX (MHSAX) and the k-medoids method. MHSAX is a hybrid symbolic aggregate approximation combining the SAX strings of a time series and its MACD histogram. By utilizing MHSAX, we can calculate the more accurate distance between time series compared with other approaches. This improves the affinity with the k-medoids method and improves the accuracy of clustering. We actually implemented the proposed clustering method and conducted experiments using the whole UCR Time Series Archive data sets. The experimental results show that the proposed method is superior to other state-of-the-art methods.},
  keywords = {Aggregates,Clustering,Clustering methods,Feature extraction,Hidden Markov models,Histograms,k-medoids,MACD Histogram,SAX,Time measurement,Time series,Time series analysis}
}

@inproceedings{tayebi2011,
  title = {{{RA}}-{{SAX}}: {{Resource}}-{{Aware Symbolic Aggregate Approximation}} for {{Mobile ECG Analysis}}},
  shorttitle = {{{RA}}-{{SAX}}},
  booktitle = {2011 {{IEEE}} 12th {{International Conference}} on {{Mobile Data Management}}},
  author = {Tayebi, H. and Krishnaswamy, S. and Waluyo, A. B. and Sinha, A. and Gaber, M. M.},
  year = {2011},
  month = jun,
  volume = {1},
  pages = {289--290},
  issn = {2375-0324},
  doi = {10.1109/MDM.2011.67},
  abstract = {There is a growing focus on 24/7 cardiac monitoring that leverages state of the art mobile phones and commercial-off-the-shelf (COTS) wearable bio-sensors. While many signal processing techniques for mobile ECG analysis have been developed, these techniques tend to be computationally intensive. In this paper, we propose, develop and evaluate a resource-aware and energy-efficient time series analysis technique for real-time ECG analysis on mobile devices based on the well-known SAX (Symbolic Aggregate Approximation) representation for time series termed RA-SAX.},
  file = {/home/moritz/Zotero/storage/2GLGVLKG/6068450.html},
  keywords = {Accuracy,approximation theory,biosensors,cardiac monitoring,Classification algorithms,Clustering algorithms,commercial-off-the-shelf,COTS,ECG,electrocardiography,Electrocardiography,medical signal processing,Mobile communication,mobile computing,Mobile Devices,mobile ECG analysis,mobile handsets,mobile phones,RA-SAX,resource aware symbolic aggregate approximation,signal processing techniques,Smart phones,symbolic aggregate approximation,Time Series}
}

@article{tseng2020,
  title = {Clustering {{Analysis}} of {{Aging Diseases}} and {{Chronic Habits With Multivariate Time Series Electrocardiogram}} and {{Medical Records}}},
  author = {Tseng, Kuo-Kun and Li, Jiaqian and Tang, Yih-Jing and Yang, Ching-Wen and Lin, Fang-Ying and Zhao, Zhaowen},
  year = {2020},
  volume = {12},
  publisher = {{Frontiers}},
  issn = {1663-4365},
  doi = {10.3389/fnagi.2020.00095},
  abstract = {Background: With recent technology, multivariate time series electrocardiogram (ECG) analysis has played an important role in diagnosing cardiovascular diseases. However, discovering the association of wide range aging disease and chronic habit with ECG analysis still has room to be explored. This paper mainly analyses the possible relationship between common aging diseases or chorionic habits of Medical Record and ECG, such as the diseases of diabetes, obesity and hypertension, or the habit of smoking. Whether there is a relationship between ECG and some common diseases and habits. Method: In the research, we firstly conducted different ECG features, such as those of reduced binary pattern (RBP), waveform, and wavelet, and then performed a k-means clustering analysis on the correlation between ECGs and the aforementioned diseases and habits, from which expected to find a firm association between them and the best characteristic used for future research. Result: In a summary, we discovered a weak and strong evidence between ECG and medical records, for the weak that the smokers might have a unique ECG feature vector enabling clustering them into specific groups, so the ECGs might be used to identify smokers and non-smokers. For a stronger evidence, most of patients with diabetes are always assigned into a specified group no matter of the number of classes in the K-means clustering, which means we can find their association between them. It is also interesting, we found that obesity and hypertension, which are thought to be related to cardiovascular system. However, they are not highly correlated in our clustering analysis, which might indirectly tell us that the impact of obesity and hypertension to our body is various.},
  file = {/home/moritz/Zotero/storage/SP9SHC7Z/Tseng et al. - 2020 - Clustering Analysis of Aging Diseases and Chronic .pdf},
  journal = {Frontiers in Aging Neuroscience},
  keywords = {Disease analysis,electrocardiogram,feature extraction,habit analysis,K-Means clustering},
  language = {English}
}

@article{wang2010,
  title = {A Tree-Construction Search Approach for Multivariate Time Series Motifs Discovery},
  author = {Wang, L. and Chng, E.s. and Li, H.},
  year = {2010},
  month = jul,
  volume = {31},
  pages = {869--875},
  issn = {01678655},
  doi = {10.1016/j.patrec.2010.01.005},
  abstract = {Abstract: This paper examines an unsupervised search method to discover motifs from multivariate time series data. Our method first scans the entire series to construct a list of candidate motifs in linear time, the list is then used to populate a sparse self-similarity matrix for further processing to generate the final selections. The proposed algorithm is efficient in both running time and memory storage. To demonstrate its effectiveness, we applied it to search for repeating segments in both music and sensory data sets. The experimental results showed that the proposed method can efficiently detect repeating segments as compared to well-known methods such as self-similarity matrix search and symbolic aggregation approximation approaches.},
  journal = {Pattern Recognition Letters},
  keywords = {APPROXIMATION theory,Information retrieval,INFORMATION retrieval,MATRICES,Motif discovery,Multidimensional sequences,MULTIVARIATE analysis,Music,PATTERN perception,Pattern recognition,SEARCH algorithms,TIME series analysis,TREE graphs},
  number = {9}
}

@article{wang2016a,
  title = {Representation {{Learning}} with {{Deconvolution}} for {{Multivariate Time Series Classification}} and {{Visualization}}},
  author = {Wang, Zhiguang and Song, Wei and Liu, Lu and Zhang, Fan and Xue, Junxiao and Ye, Yangdong and Fan, Ming and Xu, Mingliang},
  year = {2016},
  month = oct,
  abstract = {We propose a new model based on the deconvolutional networks and SAX discretization to learn the representation for multivariate time series. Deconvolutional networks fully exploit the advantage the powerful expressiveness of deep neural networks in the manner of unsupervised learning. We design a network structure specifically to capture the cross-channel correlation with deconvolution, forcing the pooling operation to perform the dimension reduction along each position in the individual channel. Discretization based on Symbolic Aggregate Approximation is applied on the feature vectors to further extract the bag of features. We show how this representation and bag of features helps on classification. A full comparison with the sequence distance based approach is provided to demonstrate the effectiveness of our approach on the standard datasets. We further build the Markov matrix from the discretized representation from the deconvolution to visualize the time series as complex networks, which show more class-specific statistical properties and clear structures with respect to different labels.},
  file = {/home/moritz/Zotero/storage/6AH8PFEY/Wang et al. - 2016 - Representation Learning with Deconvolution for Mul.pdf}
}

@article{warrenliao2005,
  title = {Clustering of Time Series Data\textemdash a Survey},
  author = {Warren Liao, T.},
  year = {2005},
  month = nov,
  volume = {38},
  pages = {1857--1874},
  issn = {00313203},
  doi = {10.1016/j.patcog.2005.01.025},
  abstract = {Time series clustering has been shown effective in providing useful information in various domains. There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains. The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research.},
  file = {/home/moritz/Documents/thesis.git/papers/warrenliao2005.pdf},
  journal = {Pattern Recognition},
  language = {en},
  number = {11}
}

@article{yu2019,
  title = {A {{Novel Trend Symbolic Aggregate Approximation}} for {{Time Series}}},
  author = {Yu, Yufeng and Zhu, Yuelong and Wan, Dingsheng and Zhao, Qun and Liu, Huan},
  year = {2019},
  volume = {abs/1905.00421},
  pages = {9},
  url = {http://arxiv.org/abs/1905.00421},
  abstract = {Symbolic Aggregate approximation (SAX) is a classical symbolic approach in many time series data mining applications. However, SAX only reflects the segment mean value feature and misses important information in a segment, namely the trend of the value change in the segment. Such a miss may cause a wrong classification in some cases, since the SAX representation cannot distinguish different time series with similar average values but different trends. In this paper, we present Trend Feature Symbolic Aggregate approximation (TFSAX) to solve this problem. First, we utilize Piecewise Aggregate Approximation (PAA) approach to reduce dimensionality and discretize the mean value of each segment by SAX. Second, extract trend feature in each segment by using trend distance factor and trend shape factor. Then, design multi-resolution symbolic mapping rules to discretize trend information into symbols. We also propose a modified distance measure by integrating the SAX distance with a weighted trend distance. We show that our distance measure has a tighter lower bound to the Euclidean distance than that of the original SAX. The experimental results on diverse time series data sets demonstrate that our proposed representation significantly outperforms the original SAX representation and an improved SAX representation for classification.},
  file = {/home/moritz/Documents/thesis.git/papers/yu2019.pdf},
  language = {en}
}

@inproceedings{yu2019a,
  title = {A {{Novel Symbolic Aggregate Approximation}} for {{Time Series}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Ubiquitous Information Management}} and {{Communication}} ({{IMCOM}}) 2019},
  author = {Yu, Yufeng and Zhu, Yuelong and Wan, Dingsheng and Liu, Huan and Zhao, Qun},
  editor = {Lee, Sukhan and Ismail, Roslan and Choo, Hyunseung},
  year = {2019},
  pages = {805--822},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-19063-7_65},
  abstract = {Symbolic Aggregate approximation (SAX) is a classical symbolic approach in many time series data mining applications. However, SAX only reflects the segment mean value feature and misses important information in a segment, namely the trend of the value change in the segment. Such a miss may cause a wrong classification in some cases, since the SAX representation cannot distinguish different time series with similar average values but different trends. In this paper, we present Trend Feature Symbolic Aggregate approximation (TFSAX) to solve this problem. First, we utilize Piecewise Aggregate Approximation (PAA) approach to reduce dimensionality and discretize the mean value of each segment by SAX. Second, extract trend feature in each segment by using trend distance factor and trend shape factor. Then, design multi-resolution symbolic mapping rules to discretize trend information into symbols. We also propose a modified distance measure by integrating the SAX distance with a weighted trend distance. We show that our distance measure has a tighter lower bound to the Euclidean distance than that of the original SAX. The experimental results on diverse time series data sets demonstrate that our proposed representation significantly outperforms the original SAX representation and an improved SAX representation for classification.},
  isbn = {978-3-030-19063-7},
  keywords = {Distance measure,Lower bound,Symbolic aggregate approximation,Time series,Trend feature},
  language = {en},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}}
}

@inproceedings{zan2016,
  title = {An Improved Symbolic Aggregate Approximation Distance Measure Based on Its Statistical Features},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Information Integration}} and {{Web}}-Based {{Applications}} and {{Services}}},
  author = {Zan, Chaw Thet and Yamana, Hayato},
  year = {2016},
  month = nov,
  pages = {72--80},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3011141.3011146},
  abstract = {The challenges in efficient data representation and similarity measures on massive amounts of time series have enormous impact on many applications. This paper addresses an improvement on Symbolic Aggregate approXimation (SAX), is one of the efficient representations for time series mining. Because SAX represents its symbols by the average (mean) value of a segment with the assumption of Gaussian distribution, it is insufficient to serve the entire deterministic information and causes sometimes incorrect results in time series classification. In this work, SAX representation and distance measure is improved with the addition of another moment of the prior distribution, standard deviation; SAX\_SD is proposed. We provide comprehensive analysis for the proposed SAX\_SD and confirm both the highest classification accuracy and the highest dimensionality reduction ratio on University of California, Riverside (UCR) datasets in comparison to state of the art methods such as SAX, Extended SAX (ESAX) and SAX Trend Distance (SAX\_TD).},
  isbn = {978-1-4503-4807-2},
  keywords = {classification,dimension reduction,statistical features,symbolic representation,time series},
  series = {{{iiWAS}} '16}
}

@article{zhang2019,
  title = {Anomaly Detection in {{ECG}} Based on Trend Symbolic Aggregate Approximation},
  author = {Zhang, Chunkai and Chen, Yingyang and Yin, Ao and Wang, Xuan and {Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China}},
  year = {2019},
  volume = {16},
  pages = {2154--2167},
  issn = {1547-1063},
  doi = {10.3934/mbe.2019105},
  abstract = {ECG anomaly detection is a necessary approach to detect disease Electrocardiography(ECG) signals before the detail diagnosis process in medical field to gauge the health of the human heart. Nowadays, there are many anomaly detection methods for ECG detection including supervised learning and unsupervised learning. For supervised learning, it requires the knowledge of expert and different types of Arrhythmia data for training. However, since the anomalies are less and unknown in many cases which are difficult to distinguish and be labeled, unsupervised methods are more suitable to detect the ECG anomalies. Furthermore, the existing unsupervised learning studies do not take ECG shape into account where different diseases have different shapes. In this paper, a novel simple trend aggregate approximation method is proposed, the relative binary trend representation are used to record the shape feature in original time series and to detect the anomaly heart signals by similarity comparison. We use the ECG dataset in UCR Time Series Classification Archive to obtain ECG time series data and the experiment results are assessed by means of sensitivity, specificity, false alarm rate measures which is robust and promising with high accuracy.},
  file = {/home/moritz/Documents/thesis.git/papers/zhang2019.pdf},
  journal = {Mathematical Biosciences and Engineering},
  keywords = {applied,ecg,method},
  language = {en},
  number = {4}
}

@article{zhang2019a,
  title = {A New Feature Extraction Approach Using Improved Symbolic Aggregate Approximation for Machinery Intelligent Diagnosis},
  author = {Zhang, Yulong and Duan, Lixiang and Duan, Menglan},
  year = {2019},
  month = feb,
  volume = {133},
  pages = {468--478},
  issn = {0263-2241},
  doi = {10.1016/j.measurement.2018.10.045},
  abstract = {Feature extraction from vibration signals is considerably significant for condition monitoring and fault diagnosis. The Symbolic Aggregate approXimation (SAX) technique essentially transforming a real-valued time series into a symbol sequence, has been proven as a potential tool of feature extraction for machinery intelligent diagnosis. However, challenge still exists that the SAX cannot fulfill feature extraction tasks well since it is carried out only on the basis of mean value in time domain. To overcome this limitation, an improved SAX (ISAX) is proposed in this paper. This new method substitutes the feature of mean value in time domain with multiple features extracted from time, frequency and time-frequency domains in order to obtain comprehensive fault information. With the ISAX transformation, a vibration signal can be transformed into various symbol sequences according to the multi-domain features. Next the Shannon entropy technique is conducted on a symbol sequence to capture sequential patterns in local signals and then the Shannon entropy value is used as the eigenvalue of the symbol sequence. Various eigenvalues are obtained to describe a vibration signal from different perspectives, which leads to a better feature extraction. These eigenvalues are then fed into the Kernel Principal Component Analysis (KPCA) to reduce dimensions and extract principal features for classification tasks. Compared with SAX, the most significant advantage of ISAX is extracting comprehensive signal characteristics from multi-domain. Moreover, the ISAX captures fault information better considering the local fault patterns. The effectiveness and superiority of ISAX were validated by experimental studies using the fault signals of rolling bearings and reciprocating compressor valves with remarkably high classification rates.},
  journal = {Measurement},
  keywords = {Bearing defect diagnosis,Fault pattern,Improved SAX,Reciprocating compressor valve,Symbolic Aggregate approXimation (SAX)},
  language = {en}
}

@article{zotero-278,
  title = {{{SAX}}-{{VSM}}: {{Interpretable Time Series Classification Using SAX}} and {{Vector Space Model}}},
  pages = {11},
  abstract = {In this paper, we propose a novel method for characteristic patterns discovery in time series. This method, called SAX-VSM, is based on two existing techniques - Symbolic Aggregate approXimation and Vector Space Model. SAX-VSM is capable to automatically discover and rank time series patterns by their importance to the class, which not only creates wellperforming classifiers and facilitates clustering, but also provides an interpretable class generalization. The accuracy of the method, as shown through experimental evaluation, is at the level of the current state of the art. While being relatively computationally expensive within a learning phase, our method provides fast, precise, and interpretable classification.},
  file = {/home/moritz/Zotero/storage/V8246E43/SAX-VSM Interpretable Time Series Classification .pdf},
  language = {en}
}

@misc{zotero-280,
  title = {A Fast Algorithm for Complex Discord Searches in Time Series: {{HOT SAX Time}}},
  shorttitle = {A Fast Algorithm for Complex Discord Searches in Time Series},
  url = {https://www.groundai.com/project/a-fast-algorithm-for-complex-discord-searches-in-time-series-hot-sax-time/1},
  urldate = {2021-03-30},
  abstract = {Time series analysis is quickly proceeding towards long and complex tasks. In recent years, fast approximate algorithms for discord search have been proposed in order to compensate for the increasing size of the time series. It is more interesting, however, to find quick exact solutions. In this research, we improved HOT SAX by exploiting two main ideas: the warm-up process, and the similarity between sequences close in time. The resulting algorithm, called HOT SAX Time (HST), has been validated with real and synthetic time series, and successfully compared with HOT SAX, RRA, SCAMP, and DADD. The complexity of a discord \ldots},
  file = {/home/moritz/Zotero/storage/5WGHTLIN/1.html},
  journal = {GroundAI},
  language = {en}
}

@misc{zotero-371,
  title = {Arrhythmia {{Essentials}} - 2nd {{Edition}}},
  url = {https://www.elsevier.com/books/arrhythmia-essentials/olshansky/978-0-323-39968-5},
  urldate = {2021-04-06},
  file = {/home/moritz/Zotero/storage/JJVGT2KA/978-0-323-39968-5.html}
}


