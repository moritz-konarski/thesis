
@article{aghabozorgi2015,
  title = {Time-Series Clustering \textendash{} {{A}} Decade Review},
  author = {Aghabozorgi, Saeed and Seyed Shirkhorshidi, Ali and Ying Wah, Teh},
  year = {2015},
  month = oct,
  volume = {53},
  pages = {16--38},
  issn = {03064379},
  doi = {10.1016/j.is.2015.04.007},
  abstract = {Clustering is a solution for classifying enormous data when there is not any early knowledge about classes. With emerging new concepts like cloud computing and big data and their vast applications in recent years, research works have been increased on unsupervised solutions like clustering algorithms to extract knowledge from this avalanche of data. Clustering time-series data has been used in diverse scientific areas to discover patterns which empower data analysts to extract valuable information from complex and massive datasets. In case of huge datasets, using supervised classification solutions is almost impossible, while clustering can solve this problem using unsupervised approaches. In this research work, the focus is on time-series data, which is one of the popular data types in clustering problems and is broadly used from gene expression data in biology to stock market analysis in finance. This review will expose four main components of time-series clustering and is aimed to represent an updated investigation on the trend of improvements in efficiency, quality and complexity of clustering time-series approaches during the last decade and enlighten new paths for future works.},
  file = {/home/moritz/Documents/thesis.git/papers/aghabozorgi2015.pdf},
  journal = {Information Systems},
  language = {en}
}

@article{alghatrif2012,
  ids = {alghatrif2012a},
  title = {A Brief Review: History to Understand Fundamentals of Electrocardiography},
  shorttitle = {A Brief Review},
  author = {AlGhatrif, Majd and Lindsay, Joseph},
  year = {2012},
  month = jan,
  volume = {2},
  pages = {14383},
  issn = {2000-9666},
  doi = {10.3402/jchimp.v2i1.14383},
  abstract = {Since Einthoven's original electrocardiogram, half a century passed until it evolved into the 12-lead electrocardiogram as we know it now. In each step in this seemingly slow process, physicians embraced the electrocardiogram as an essential clinical instrument; however, with time, they recognized the deficiencies in those earlier limited versions. It was this recognition of deficiency that pushed physicians and scientists to improve this technology allowing the optimization of this non-invasive tool.},
  file = {/home/moritz/Documents/thesis.git/papers/alghatrif2012.pdf;/home/moritz/Documents/thesis.git/papers/alghatrif2012.pdf},
  journal = {Journal of Community Hospital Internal Medicine Perspectives},
  language = {en},
  number = {1}
}

@inproceedings{anacleto2020,
  title = {{{MSAX}}: {{Multivariate Symbolic Aggregate Approximation}} for {{Time Series Classification}}},
  shorttitle = {{{MSAX}}},
  booktitle = {Computational {{Intelligence Methods}} for {{Bioinformatics}} and {{Biostatistics}}},
  author = {Anacleto, Manuel and Vinga, Susana and Carvalho, Alexandra M.},
  editor = {Cazzaniga, Paolo and Besozzi, Daniela and Merelli, Ivan and Manzoni, Luca},
  year = {2020},
  pages = {90--97},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-63061-4_9},
  abstract = {Time Series (TS) analysis is a central research topic in areas such as finance, bioinformatics, and weather forecasting, where the goal is to extract knowledge through data mining techniques. Symbolic aggregate approximation (SAX) is a state-of-the-art method that performs discretization and dimensionality reduction for univariate TS, which are key steps for TS representation and analysis. In this work, we propose MSAX, an extension of this algorithm to multivariate TS that takes into account the covariance structure of the data. The method is tested in several datasets, including the Pen Digits, Character Trajectories, and twelve benchmark files. Depending on the experiment, MSAX exhibits comparable performance with state-of-the-art methods in terms of classification accuracy. Although not superior to 1-nearest neighbor (1-NN) and dynamic time warping (DTW), it has interesting characteristics for some classes, and thus enriches the set of methods to analyze multivariate TS.},
  file = {/home/moritz/Zotero/storage/PL3PF9LW/Anacleto et al. - 2020 - MSAX Multivariate Symbolic Aggregate Approximatio.pdf},
  isbn = {978-3-030-63061-4},
  keywords = {Classification,Multivariate analysis,Symbolic aggregate approximation,Time series},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{ansari2017,
  title = {A {{Review}} of {{Automated Methods}} for {{Detection}} of {{Myocardial Ischemia}} and {{Infarction Using Electrocardiogram}} and {{Electronic Health Records}}},
  author = {Ansari, Sardar and Farzaneh, Negar and Duda, Marlena and Horan, Kelsey and Andersson, Hedvig B. and Goldberger, Zachary D. and Nallamothu, Brahmajee K. and Najarian, Kayvan},
  year = {2017},
  volume = {10},
  pages = {264--298},
  issn = {1937-3333, 1941-1189},
  doi = {10.1109/RBME.2017.2757953},
  file = {/home/moritz/Downloads/IschemiadetectionECG.pdf},
  journal = {IEEE Reviews in Biomedical Engineering},
  language = {en}
}

@article{antzelevitch2011,
  title = {Overview of {{Basic Mechanisms}} of {{Cardiac Arrhythmia}}},
  author = {Antzelevitch, Charles and Burashnikov, Alexander},
  year = {2011},
  month = mar,
  volume = {3},
  pages = {23--45},
  issn = {1877-9182},
  doi = {10.1016/j.ccep.2010.10.012},
  file = {/home/moritz/Zotero/storage/R8X5WIGN/Antzelevitch and Burashnikov - 2011 - Overview of Basic Mechanisms of Cardiac Arrhythmia.pdf},
  journal = {Cardiac electrophysiology clinics},
  number = {1},
  pmcid = {PMC3164530},
  pmid = {21892379}
}

@article{aremu2019,
  title = {A {{Relative Entropy Weibull}}-{{SAX}} Framework for Health Indices Construction and Health Stage Division in Degradation Modeling of Multivariate Time Series Asset Data},
  author = {Aremu, Oluseun Omotola and {Hyland-Wood}, David and McAree, Peter Ross},
  year = {2019},
  month = apr,
  volume = {40},
  pages = {121--134},
  issn = {1474-0346},
  doi = {10.1016/j.aei.2019.03.003},
  abstract = {Predictive maintenance is the monitoring of an asset's condition over its life cycle to provide a prognosis for when maintenance is required. Prior to prognosis, an asset's life cycle is modeled by a health indicator (HI) which is derived from sensor measurements and describes an asset's degradation over a life cycle. Often an asset's HI is accompanied by a health stage (HS) division, which describes the asset's life cycle condition in discrete states. Generally, HSs are discrete representations generated from discrete state transition models, dynamic state space models, or subjectively defined thresholds, which use sensor measurements to provide a HS division related to an asset's life cycle degradation. HS division methods are often designed for a specific asset in which HS division is based on user assumptions and not generalizable to different asset types or asset data representations. Also, HS division methods are often limited to a bi-state HS division (normal and failure), in which unobservable states are often generalized transition states. As assets become more complex and require multivariate measurements, more advanced methods are required to model an asset's degradation using HIs and HSs. This work introduces Relative Entropy Weibull-SAX (REWS), a data-driven HI and HS degradation modeling method for multivariate asset data. REWS constructs a HI using relative entropy to represent an asset's condition as a change of entropy during its life cycle. The relative entropy representation is then discretized into HS divisions using a Weibull distribution based Symbolic Aggregate approXimation. REWS's utility is demonstrated on the Commercial Modular Aero-Propulsion System Simulation dataset which describes the life cycle observations of multiple aircraft engines.},
  file = {/home/moritz/Zotero/storage/VQIU3N4J/S1474034618305603.html},
  journal = {Advanced Engineering Informatics},
  keywords = {Condition monitoring,Hidden Markov model,Information theory,Kalman filter,Machine learning,Predictive maintenance,Relative entropy,Weibull distribution},
  language = {en}
}

@article{baim1986,
  title = {Survival of Patients with Severe Congestive Heart Failure Treated with Oral Milrinone},
  author = {Baim, Donald S. and Colucci, Wilson S. and Monrad, E. Scott and Smith, Harton S. and Wright, Richard F. and Lanoue, Alyce and Gauthier, Diane F. and Ransil, Bernard J. and Grossman, William and Braunwald, Eugene},
  year = {1986},
  month = mar,
  volume = {7},
  pages = {661--670},
  issn = {07351097},
  doi = {10.1016/S0735-1097(86)80478-8},
  file = {/home/moritz/Documents/thesis.git/papers/baim1985.pdf},
  journal = {Journal of the American College of Cardiology},
  language = {en},
  number = {3}
}

@article{becker2006,
  title = {Fundamentals of {{Electrocardiography Interpretation}}},
  author = {Becker, Daniel E},
  year = {2006},
  volume = {53},
  pages = {53--64},
  issn = {0003-3006},
  doi = {10.2344/0003-3006(2006)53[53:FOEI]2.0.CO;2},
  abstract = {The use of dynamic electrocardiogram (ECG) monitoring is regarded as a standard of care during general anesthesia and is strongly encouraged when providing deep sedation. Although significant cardiovascular changes rarely if ever can be attributed to mild or moderate sedation techniques, the American Dental Association recommends ECG monitoring for patients with significant cardiovascular disease. The purpose of this continuing education article is to review basic principals of ECG monitoring and interpretation.},
  file = {/home/moritz/Zotero/storage/3KVQHEPC/Becker - 2006 - Fundamentals of Electrocardiography Interpretation.pdf},
  journal = {Anesthesia Progress},
  number = {2},
  pmcid = {PMC1614214},
  pmid = {16863387}
}

@book{brockwell2016,
  title = {Introduction to {{Time Series}} and {{Forecasting}}},
  author = {Brockwell, Peter J. and Davis, Richard A.},
  year = {2016},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-29854-2},
  file = {/home/moritz/Documents/thesis.git/papers/brockwell2016.pdf},
  isbn = {978-3-319-29852-8 978-3-319-29854-2},
  language = {en},
  series = {Springer {{Texts}} in {{Statistics}}}
}

@inproceedings{camerra2010,
  ids = {camerra2010a},
  title = {{{iSAX}} 2.0: {{Indexing}} and {{Mining One Billion Time Series}}},
  shorttitle = {{{iSAX}} 2.0},
  booktitle = {Proceedings - {{IEEE International Conference}} on {{Data Mining}}, {{ICDM}}},
  author = {Camerra, Alessandro and Palpanas, Themis and Shieh, Jin and Keogh, Eamonn},
  year = {2010},
  month = dec,
  pages = {58--67},
  doi = {10.1109/ICDM.2010.124},
  abstract = {There is an increasingly pressing need, by several applications in diverse domains, for developing techniques able to index and mine very large collections of time series. Examples of such applications come from astronomy, biology, the web, and other domains. It is not unusual for these applications to involve numbers of time series in the order of hundreds of millions to billions. However, all relevant techniques that have been proposed in the literature so far have not considered any data collections much larger than one-million time series. In this paper, we describe iSAX 2.0, a data structure designed for indexing and mining truly massive collections of time series. We show that the main bottleneck in mining such massive datasets is the time taken to build the index, and we thus introduce a novel bulk loading mechanism, the first of this kind specifically tailored to a time series index. We show how our method allows mining on datasets that would otherwise be completely untenable, including the first published experiments to index one billion time series, and experiments in mining massive data from domains as diverse as entomology, DNA and web-scale image collections.},
  file = {/home/moritz/Downloads/iSAX_20_Indexing_and_Mining_One_Billion_Time_Serie.pdf;/home/moritz/Zotero/storage/V5NHD8LB/Camerra et al. - 2010 - iSAX 2.0 Indexing and Mining One Billion Time Ser.pdf}
}

@article{cerna2000,
  title = {The {{Fundamentals}} of {{FFT}}-{{Based Signal Analysis}} and {{Measurement}}},
  author = {Cerna, Michael and Harvey, Audrey F},
  year = {2000},
  month = jul,
  pages = {20},
  file = {/home/moritz/Zotero/storage/B6HE4A2L/Cerna and Harvey - The Fundamentals of FFT-Based Signal Analysis and .pdf},
  language = {en}
}

@article{corduas2008,
  title = {Time Series Clustering and Classification by the Autoregressive Metric},
  author = {Corduas, Marcella and Piccolo, Domenico},
  year = {2008},
  month = jan,
  volume = {52},
  pages = {1860--1872},
  issn = {01679473},
  doi = {10.1016/j.csda.2007.06.001},
  abstract = {The statistical properties of the autoregressive (AR) distance between ARIMA processes are investigated. In particular, the asymptotic distribution of the squared AR distance and an approximation which is computationally efficient are derived. Moreover, the problem of time series clustering and classification is discussed and the performance of the AR distance is illustrated by means of some empirical applications.},
  file = {/home/moritz/Documents/thesis.git/papers/corduas2008.pdf},
  journal = {Computational Statistics \& Data Analysis},
  language = {en},
  number = {4}
}

@article{das2013,
  title = {Fractional Dynamical Model for the Generation of {{ECG}} like Signals from Filtered Coupled {{Van}}-Der {{Pol}} Oscillators},
  author = {Das, Saptarshi and Maharatna, Koushik},
  year = {2013},
  month = dec,
  volume = {112},
  pages = {490--507},
  issn = {01692607},
  doi = {10.1016/j.cmpb.2013.08.012},
  abstract = {In this paper, an incommensurate fractional order (FO) model has been proposed to generate ECG like waveforms. Earlier investigation of ECG like waveform generation is based on two identical Van-der Pol (VdP) family of oscillators which are coupled by time delays and gains. In this paper, we suitably modify the three state equations corresponding to the nonlinear cross-product of states, time delay coupling of the two oscillators and low-pass filtering, using the concept of fractional derivatives. Our results show that a wide variety of ECG like waveforms can be simulated from the proposed generalized models, characterizing heart conditions under different physiological conditions. Such generalization of the modelling of ECG waveforms may be useful to understand the physiological process behind ECG signal generation in normal and abnormal heart conditions. Along with the proposed FO models, an optimization based approach is also presented to estimate the VdP oscillator parameters for representing a realistic ECG like signal.},
  file = {/home/moritz/Documents/thesis.git/papers/das2013.pdf},
  journal = {Computer Methods and Programs in Biomedicine},
  language = {en},
  number = {3}
}

@article{durham2002,
  title = {Cardiac Arrhythmias: Diagnosis and Management. {{The}} Tachycardias},
  shorttitle = {Cardiac Arrhythmias},
  author = {Durham, D. and Worthley, L. I. G.},
  year = {2002},
  month = mar,
  volume = {4},
  pages = {35--53},
  issn = {1441-2772},
  abstract = {OBJECTIVE: To review the diagnosis and management of cardiac arrhythmias in a two-part presentation. DATA SOURCES: Articles and published peer-review abstracts on tachycardias and bradycardias. SUMMARY OF REVIEW: Normal cardiac rhythm originates from impulses generated within the sinus node. These impulses are conducted to the atrioventricular node where they are delayed before they are distributed to the ventricular myocardium via the His-Purkinje system. Abnormalities in cardiac rhythm are caused by disorders of impulse generation, conduction or a combination of the two and may be life threatening due to a reduction in cardiac output or myocardial oxygenation. Cardiac arrhythmias are commonly classified as tachycardias (supraventricular or ventricular) or bradycardias. The differentiation between supraventricular and ventricular tachycardias usually requires an assessment of atrial and ventricular rhythms and their relationship to each other. In the critically ill patient the commonest tachycardia is sinus tachycardia and treatment generally consist of management of the underlying disorder. Other supraventricular tachycardias (SVTs) include, atrial flutter, atrial fibrillation and paroxysmal supraventricular tachycardia (PSVT) all of which may require cardioversion, although to maintain sinus rhythm, antiarrhythmic therapy is often needed. Adenosine is useful in management and treatment many SVTs although its use in PSVT with Wolff-Parkinson-White syndrome is hazardous. Multifocal atrial tachycardia is a characteristic supraventricular tachycardia found in the critical ill patient. While it usually responds to intravenous magnesium sulphate, its management also requires removal of various precipitating factors. Ventricular tachycardia (VT) and ventricular fibrillation (VF) require urgent cardioversion and defibrillation respectively. Torsade de pointes should be differentiated from these ventricular arrhythmias as antiarrhythmic therapy may be contraindicated. CONCLUSIONS: Supraventricular and ventricular tachycardias in the critically ill patient often have underlying disorders that precipitate their development (e.g. hypokalaemia, hypomagnesaemia, anti-arrhythmic proarrhythmia, myocardial ischaemia, etc). While antiarrhythmic therapy and cardioversion or defibrillation may be required to achieve sinus rhythm, correction of the associated abnormalities is also required.},
  journal = {Critical Care and Resuscitation: Journal of the Australasian Academy of Critical Care Medicine},
  language = {eng},
  number = {1},
  pmid = {16573402}
}

@inproceedings{esmael2012,
  ids = {esmael2012a},
  title = {Multivariate {{Time Series Classification}} by {{Combining Trend}}-{{Based}} and {{Value}}-{{Based Approximations}}},
  booktitle = {Computational {{Science}} and {{Its Applications}} \textendash{} {{ICCSA}} 2012},
  author = {Esmael, Bilal and Arnaout, Arghad and Fruhwirth, Rudolf K. and Thonhauser, Gerhard},
  editor = {Murgante, Beniamino and Gervasi, Osvaldo and Misra, Sanjay and Nedjah, Nadia and Rocha, Ana Maria A. C. and Taniar, David and Apduhan, Bernady O.},
  year = {2012},
  pages = {392--403},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-31128-4_29},
  abstract = {Multivariate time series data often have a very high dimensionality. Classifying such high dimensional data poses a challenge because a vast number of features can be extracted. Furthermore, the meaning of the normally intuitive term ``similar to'' needs to be precisely defined. Representing the time series data effectively is an essential task for decision-making activities such as prediction, clustering and classification. In this paper we propose a feature-based classification approach to classify real-world multivariate time series generated by drilling rig sensors in the oil and gas industry. Our approach encompasses two main phases: representation and classification.For the representation phase, we propose a novel representation of time series which combines trend-based and value-based approximations (we abbreviate it as TVA). It produces a compact representation of the time series which consists of symbolic strings that represent the trends and the values of each variable in the series. The TVA representation improves both the accuracy and the running time of the classification process by extracting a set of informative features suitable for common classifiers.For the classification phase, we propose a memory-based classifier which takes into account the antecedent results of the classification process. The inputs of the proposed classifier are the TVA features computed from the current segment, as well as the predicted class of the previous segment.Our experimental results on real-world multivariate time series show that our approach enables highly accurate and fast classification of multivariate time series.},
  file = {/home/moritz/Zotero/storage/ELDRFXWC/Esmael et al. - 2012 - Multivariate Time Series Classification by Combini.pdf},
  isbn = {978-3-642-31128-4},
  keywords = {Event Detection,Symbolic Aggregate Approximation,Time Series Classification,Time Series Representation},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@inproceedings{fuad2010,
  title = {{{TOWARDS A FASTER SYMBOLIC AGGREGATE APPROXIMATION METHOD}}:},
  shorttitle = {{{TOWARDS A FASTER SYMBOLIC AGGREGATE APPROXIMATION METHOD}}},
  booktitle = {Proceedings of the 5th {{International Conference}} on {{Software}} and {{Data Technologies}}},
  author = {Fuad, Muhammad Marwan Muhammad and Marteau, Pierre-Fran{\c c}ois},
  year = {2010},
  pages = {305--310},
  publisher = {{SciTePress - Science and and Technology Publications}},
  address = {{University of Piraeus, Greece}},
  doi = {10.5220/0003006703050310},
  file = {/home/moritz/Zotero/storage/YGIEBV4P/2010 - TOWARDS A FASTER SYMBOLIC AGGREGATE APPROXIMATION .pdf},
  isbn = {978-989-8425-22-5 978-989-8425-23-2},
  language = {en}
}

@article{fye1994,
  ids = {fye1994a},
  title = {A {{History}} of the Origin, Evolution, and Impact of Electrocardiography},
  author = {Fye, W.Bruce},
  year = {1994},
  month = may,
  volume = {73},
  pages = {937--949},
  issn = {00029149},
  doi = {10.1016/0002-9149(94)90135-X},
  file = {/home/moritz/Documents/thesis.git/papers/fye1994.pdf},
  journal = {The American Journal of Cardiology},
  language = {en},
  number = {13}
}

@article{goldberger2000,
  title = {{{PhysioBank}}, {{PhysioToolkit}}, and {{PhysioNet}}: {{Components}} of a {{New Research Resource}} for {{Complex Physiologic Signals}}},
  shorttitle = {{{PhysioBank}}, {{PhysioToolkit}}, and {{PhysioNet}}},
  author = {Goldberger, Ary L. and Amaral, Luis A. N. and Glass, Leon and Hausdorff, Jeffrey M. and Ivanov, Plamen Ch. and Mark, Roger G. and Mietus, Joseph E. and Moody, George B. and Peng, Chung-Kang and Stanley, H. Eugene},
  year = {2000},
  month = jun,
  volume = {101},
  issn = {0009-7322, 1524-4539},
  doi = {10.1161/01.CIR.101.23.e215},
  file = {/home/moritz/Documents/thesis.git/papers/goldberger2000.pdf},
  journal = {Circulation},
  language = {en},
  number = {23}
}

@book{guigou2017,
  title = {Anomaly Detection and Motif Discovery in Symbolic Representations of Time Series},
  author = {Guigou, Fabio and Collet, Pierre and Parrend, Pierre},
  year = {2017},
  month = apr,
  doi = {10.13140/RG.2.2.20158.69447},
  abstract = {The advent of the Big Data hype and the consistent recollection of event logs and real-time data from sensors, monitoring software and machine configuration has generated a huge amount of time-varying data in about every sector of the industry. Rule-based processing of such data has ceased to be relevant in many scenarios where anomaly detection and pattern mining have to be entirely accomplished by the machine. Since the early 2000s, the de-facto standard for representing time series has been the Symbolic Aggregate approXimation (SAX). In this document, we present a few algorithms using this representation for anomaly detection and motif discovery, also known as pattern mining, in such data. We propose a benchmark of anomaly detection algorithms using data from Cloud monitoring software.},
  file = {/home/moritz/Zotero/storage/Y3ML5C2Q/Guigou et al. - 2017 - Anomaly detection and motif discovery in symbolic .pdf},
  keywords = {Anomaly detection,Pattern mining,Symbolic representation,Time series}
}

@article{he2020,
  ids = {he2020a},
  title = {A {{Boundary Distance}}-{{Based Symbolic Aggregate Approximation Method}} for {{Time Series Data}}},
  author = {He, Zhenwen and Long, Shirong and Ma, Xiaogang and Zhao, Hong},
  year = {2020},
  month = nov,
  volume = {13},
  pages = {284},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/a13110284},
  abstract = {A large amount of time series data is being generated every day in a wide range of sensor application domains. The symbolic aggregate approximation (SAX) is a well-known time series representation method, which has a lower bound to Euclidean distance and may discretize continuous time series. SAX has been widely used for applications in various domains, such as mobile data management, financial investment, and shape discovery. However, the SAX representation has a limitation: Symbols are mapped from the average values of segments, but SAX does not consider the boundary distance in the segments. Different segments with similar average values may be mapped to the same symbols, and the SAX distance between them is 0. In this paper, we propose a novel representation named SAX-BD (boundary distance) by integrating the SAX distance with a weighted boundary distance. The experimental results show that SAX-BD significantly outperforms the SAX representation, ESAX representation, and SAX-TD representation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {/home/moritz/Zotero/storage/35HA5BEW/He et al. - 2020 - A Boundary Distance-Based Symbolic Aggregate Appro.pdf;/home/moritz/Zotero/storage/RW3YL2HA/He et al. - 2020 - A Boundary Distance-Based Symbolic Aggregate Appro.pdf;/home/moritz/Zotero/storage/FHEE5SE6/899e8d83f76140c186abca16f08d2ef5.html;/home/moritz/Zotero/storage/YFDBPPRM/284.html},
  journal = {Algorithms},
  keywords = {ESAX,SAX,SAX-BD,SAX-TD,time series},
  language = {en},
  number = {11}
}

@article{herring2006,
  title = {{{ECG}} Diagnosis of Acute Ischaemia and Infarction: Past, Present and Future},
  shorttitle = {{{ECG}} Diagnosis of Acute Ischaemia and Infarction},
  author = {Herring, N.},
  year = {2006},
  month = feb,
  volume = {99},
  pages = {219--230},
  issn = {1460-2725, 1460-2393},
  doi = {10.1093/qjmed/hcl025},
  file = {/home/moritz/Documents/thesis.git/papers/herring2006.pdf},
  journal = {QJM},
  language = {en},
  number = {4}
}

@inproceedings{hughes2003,
  title = {Markov {{Models}} for {{Automated ECG Interval Analysis}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 16 [{{Neural Information Systems}}, \{\vphantom\}{{NIPS}}\vphantom\{\} 2003, {{December}} 8-13, 2003, {{Vancouver}} and {{Whistler}}, {{British Columbia}}, {{Canada}}]},
  author = {Hughes, Nicholas P and Tarassenko, Lionel and Roberts, Stephen J},
  year = {2003},
  pages = {611--618},
  publisher = {{MIT Press}},
  address = {{Vancouver Whistler, British Columbia, Canada}},
  url = {https://proceedings.neurips.cc/paper/2003/hash/b23975176653284f1f7356ba5539cfcb-Abstract.html},
  abstract = {We examine the use of hidden Markov and hidden semi-Markov models for automatically segmenting an electrocardiogram waveform into its constituent waveform features. An undecimated wavelet transform is used to generate an overcomplete representation of the signal that is more appropriate for subsequent modelling. We show that the state durations implicit in a standard hidden Markov model are ill-suited to those of real ECG features, and we investigate the use of hidden semi-Markov models for improved state duration modelling.},
  file = {/home/moritz/Documents/thesis.git/papers/hughes2003.pdf},
  language = {en}
}

@article{ieva2013a,
  title = {Multivariate Functional Clustering for the Morphological Analysis of Electrocardiograph Curves},
  author = {Ieva, Francesca and Paganoni, Anna M. and Pigoli, Davide and Vitelli, Valeria},
  year = {2013},
  volume = {62},
  pages = {401--418},
  publisher = {{[Wiley, Royal Statistical Society]}},
  issn = {0035-9254},
  url = {https://www.jstor.org/stable/24771812},
  urldate = {2021-03-30},
  abstract = {Cardiovascular ischaemic diseases are one of the main causes of death all over the world. In this class of pathologies, a quick diagnosis is essential for a good prognosis in reperfusive treatment. In particular, an automatic classification procedure based on statistical analysis of teletransmitted electrocardiograph ('ECG') traces would be very helpful for an early diagnosis. This work presents an analysis of ECG traces, either physiological or pathological, of patients whose 12-lead prehospital ECG has been sent to the 118 Dispatch Center in Milan by life-support personnel. The statistical analysis starts with a preprocessing step, where functional data are reconstructed from noisy observations and biological variability is removed by a non-linear registration procedure. Then, a multivariate functional k-means clustering procedure is carried out on reconstructed and registered ECGs and their first derivatives. Hence, a new semi-automatic diagnostic procedure, based solely on the ECG morphology, is proposed to classify ECG traces; finally, the performance of this classification method is evaluated.},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {3}
}

@incollection{ihd2010,
  title = {Ischemic {{Heart Disease}}},
  booktitle = {Cardiovascular {{Disability}}: {{Updating}} the {{Social Security Listings}}},
  author = {{Institute of Medicine (US) Committee on Social Security Cardiovascular Disability Criteria}},
  year = {2010},
  publisher = {{National Academies Press (US)}},
  address = {{Washington, DC}},
  url = {https://www.ncbi.nlm.nih.gov/books/NBK209964/},
  urldate = {2021-05-21},
  abstract = {This chapter describes the evaluation and management of ischemic heart disease, which has evolved significantly over the past decade. In particular, several clinical trials have documented the benefits of revascularization in patients with acute ischemic syndromes as well as the efficacy of medical therapy, including lifestyle modification in patients with stable coronary disease. A fundamental premise in establishing new listing criteria for ischemic heart disease disability is the linking of anatomic or structural evidence of coronary heart disease (CHD) with both functional impairment and severe anginal symptoms. A flow diagram has been introduced that depicts five pathways to meet listings, including clinical, standard exercise testing, stress imaging, and angiographic anatomic criteria, with one pathway specific for patients with prior coronary artery bypass graft and severe CHD. Because many patients with ischemic heart disease are unable to exercise, standard stress electrocardiographic criteria for ischemia (the sole determinant of objective ischemia assessment in prior cardiovascular disability listings) have been expanded significantly to encompass nonexercise modalities (including nuclear imaging and echocardiography provoked by pharmacologic vasodilator stress) to assess the presence of severe inducible ischemia that, when combined with severe angina (Canadian Cardiovascular Society Class III or IV) would meet a cardiovascular disability listing. Additionally, the criteria by which angiographic CHD meet a listing have been specified, and severe CHD is defined by greater than or equal to 50 percent left main stenosis and/or greater than or equal to 70 percent proximal/mid stenoses in greater than or equal to two native arteries or bypass grafts. These updated criteria now provide a significantly enhanced and evidence-based approach for making disability determinations based on anatomic and functional criteria in patients with severe angina.},
  file = {/home/moritz/Zotero/storage/43MEI7GA/NBK209964.html},
  language = {en}
}

@inproceedings{javed2014,
  title = {An Adaptive Noise Cancelation Model for Removal of Noise from Modeled {{ECG}} Signals},
  booktitle = {2014 {{IEEE REGION}} 10 {{SYMPOSIUM}}},
  author = {Javed, Shazia and Ahmad, Noor Atinah},
  year = {2014},
  month = apr,
  pages = {471--475},
  publisher = {{IEEE}},
  address = {{Kuala Lumpur, Malaysia}},
  doi = {10.1109/TENCONSpring.2014.6863079},
  abstract = {In this paper an adaptive noise cancelation (ANC) model is presented to remove baseline wander (BW) noise from mathematically modeled ECG signals. The ANC model is designed to have a trade-off between the correlation properties of noise and reference signals. Matlab is used to simulate ECG signals artificially, to represent different sinus rhythms and leads of ECG waveform. Furthermore contamination of an important artifact (baseline wander) is simulated for normal ECG lead II, and then identified using LMS algorithm and its preconditioned versions: NLMS and TDLMS algorithms, to get denoised ECG signals. Experimental results are presented for a comparison of these adaptive algorithm, which shows preference of TDLMS algorithm over the rest.},
  file = {/home/moritz/Documents/thesis.git/papers/javed2014.pdf},
  isbn = {978-1-4799-2027-3 978-1-4799-2028-0},
  language = {en}
}

@incollection{javed2019,
  ids = {javed2019a,javed2019b},
  title = {Mathematical {{Modeling}} of {{Real Time ECG Waveform}}},
  booktitle = {Intelligent {{Computing}}},
  author = {Javed, Shazia and Ahmad, Noor Atinah},
  editor = {Arai, Kohei and Kapoor, Supriya and Bhatia, Rahul},
  year = {2019},
  volume = {858},
  pages = {606--614},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-01174-1_46},
  abstract = {Electrocardiogram (ECG) is a digital recording of heart rate variability that is used to detect the cardiac disorders. Often these recordings are affected by physiological and instrumental noises that affects an accurate diagnosis of the disease. An exact understanding of ECG waveform may help in overcoming such issues. Mathematical modeling is efficiently used to understand the pattern of 12-lead ECG and simulate real time ECG's waveform. Real ECG can be taken as a superposition of bounded functions and this property is a defining feature of almost periodic functions (APF). The proposed model has utilized this characteristic of ECG signals to generate the real time ECG waveform with negligibly small error.},
  file = {/home/moritz/Documents/thesis.git/papers/javed2019.pdf},
  isbn = {978-3-030-01173-4 978-3-030-01174-1},
  language = {en}
}

@article{kadish2001,
  title = {{{ACC}}/{{AHA Clinical Competence Statement}} on {{Electrocardiography}} and {{Ambulatory Electrocardiography}}},
  author = {Kadish, Alan H. and Buxton, Alfred E. and Kennedy, Harold L. and Knight, Bradley P. and Mason, Jay W. and Schuger, Claudio D. and Tracy, Cynthia M. and Winters, William L. and Boone, Alan W. and Elnicki, Michael and Hirshfeld, John W. and Lorell, Beverly H. and Rodgers, George P. and Tracy, Cynthia M. and Weitz, Howard H.},
  year = {2001},
  month = dec,
  volume = {104},
  pages = {3169--3178},
  publisher = {{American Heart Association}},
  doi = {10.1161/circ.104.25.3169},
  file = {/home/moritz/Zotero/storage/U2VTVCC6/null et al. - 2001 - ACCAHA Clinical Competence Statement on Electroca.pdf;/home/moritz/Zotero/storage/WBHNBEBJ/circ.104.25.html},
  journal = {Circulation},
  number = {25}
}

@article{kanani2020,
  title = {{{ECG Heartbeat Arrhythmia Classification Using Time}}-{{Series Augmented Signals}} and {{Deep Learning Approach}}},
  author = {Kanani, Pratik and Padole, Mamta},
  year = {2020},
  month = jan,
  volume = {171},
  pages = {524--531},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2020.04.056},
  abstract = {Electrocardiogram (ECG) signals are the best way to monitor the functionality and health of the cardiovascular system and also identify ailments related to it. Abnormal heartbeats are reflected in the ECG pattern and such abnormal signals are called as Arrhythmias. Automated classification and identification of the ECG arrhythmia signal that provides faster and more accurate result is increasingly becoming the need of the moment. Various machine learning skills have been applied to advance the accuracy of results and increase the speed and robustness of the models. A lot of focus has been given to the architectures and datasets employed but preprocessing of the data being equally important. In this paper, a preprocessing technique that significantly improves the accuracy of the deep learning models used for ECG classification is proposed with a modified deep learning architecture that adds to the training stability. With this preprocessing technique and deep learning model, the system is able to attain accuracy levels of more than 99\% without overfitting the model.},
  file = {/home/moritz/Zotero/storage/6QYQYM9L/Kanani and Padole - 2020 - ECG Heartbeat Arrhythmia Classification Using Time.pdf},
  journal = {Procedia Computer Science},
  keywords = {accuracy,Arrhythmias,Augmentation,Deep Learning,ECG,Optimizer,stability,transformations},
  language = {en},
  series = {Third {{International Conference}} on {{Computing}} and {{Network Communications}} ({{CoCoNet}}'19)}
}

@article{kaur2016,
  ids = {kaur2016a},
  title = {{{ECG Signal Analysis}} and {{Arrhythmia Detection}} Using {{Wavelet Transform}}},
  author = {Kaur, Inderbir and Rajni, Rajni and Marwaha, Anupma},
  year = {2016},
  month = dec,
  volume = {97},
  pages = {499--507},
  issn = {2250-2106, 2250-2114},
  doi = {10.1007/s40031-016-0247-3},
  abstract = {Electrocardiogram (ECG) is used to record the electrical activity of the heart. The ECG signal being nonstationary in nature, makes the analysis and interpretation of the signal very difficult. Hence accurate analysis of ECG signal with a powerful tool like discrete wavelet transform (DWT) becomes imperative. In this paper, ECG signal is denoised to remove the artifacts and analyzed using Wavelet Transform to detect the QRS complex and arrhythmia. This work is implemented in MATLAB software for MIT/BIH Arrhythmia database and yields the sensitivity of 99.85 \%, positive predictivity of 99.92 \% and detection error rate of 0.221 \% with wavelet transform. It is also inferred that DWT outperforms principle component analysis technique in detection of ECG signal.},
  file = {/home/moritz/Documents/thesis.git/papers/kaur2016.pdf},
  journal = {Journal of The Institution of Engineers (India): Series B},
  language = {en},
  number = {4}
}

@article{keogh,
  title = {On the {{Need}} for {{Time Series Data Mining Benchmarks}}: {{A Survey}} and {{Empirical Demonstration}}},
  author = {Keogh, Eamonn and Kasetty, Shruti},
  pages = {10},
  abstract = {In the last decade there has been an explosion of interest in mining time series data. Literally hundreds of papers have introduced new algorithms to index, classify, cluster and segment time series. In this work we make the following claim. Much of this work has very little utility because the contribution made (speed in'the case of indexing, accuracy in the case of classification and clustering, model accuracy in the case of segmentation) offer an amount of "improvement" that would have been completely dwarfed by the variance that would have been observed by testing on many real world datasets, or the variance that would have been observed by changing minor (unstated) implementation details.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2002.pdf},
  language = {en}
}

@inproceedings{keogh2005,
  title = {{{HOT SAX}}: {{Efficiently Finding}} the {{Most Unusual Time Series Subsequence}}},
  shorttitle = {{{HOT SAX}}},
  booktitle = {Fifth {{IEEE International Conference}} on {{Data Mining}} ({{ICDM}}'05)},
  author = {Keogh, E. and Lin, J. and Fu, A.},
  year = {2005},
  pages = {226--233},
  publisher = {{IEEE}},
  address = {{Houston, TX, USA}},
  doi = {10.1109/ICDM.2005.79},
  abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of a longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. Time series discords have many uses for data mining, including improving the quality of clustering, data cleaning, summarization, and anomaly detection. As we will show, discords are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. We evaluate our work with a comprehensive set of experiments. In particular, we demonstrate the utility of discords with objective experiments on domains as diverse as Space Shuttle telemetry monitoring, medicine, surveillance, and industry, and we demonstrate the effectiveness of our discord discovery algorithm with more than one million experiments, on 82 different datasets from diverse domains.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2005.pdf},
  isbn = {978-0-7695-2278-4},
  language = {en}
}

@article{keogh2006,
  title = {Finding the Most Unusual Time Series Subsequence: Algorithms and Applications},
  shorttitle = {Finding the Most Unusual Time Series Subsequence},
  author = {Keogh, Eamonn and Lin, Jessica and Lee, Sang-Hee and Herle, Helga Van},
  year = {2006},
  month = dec,
  volume = {11},
  pages = {1--27},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-006-0034-6},
  abstract = {In this work we introduce the new problem of finding time series discords. Time series discords are subsequences of longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. While discords have many uses for data mining, they are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence) unlike most anomaly detection algorithms that typically require many parameters. While the brute force algorithm to discover time series discords is quadratic in the length of the time series, we show a simple algorithm that is three to four orders of magnitude faster than brute force, while guaranteed to produce identical results. We evaluate our work with a comprehensive set of experiments on diverse data sources including electrocardiograms, space telemetry, respiration physiology, anthropological and video datasets.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2006a.pdf},
  journal = {Knowledge and Information Systems},
  language = {en},
  number = {1}
}

@article{keogh2006a,
  title = {Finding {{Unusual Medical Time}}-{{Series Subsequences}}: {{Algorithms}} and {{Applications}}},
  shorttitle = {Finding {{Unusual Medical Time}}-{{Series Subsequences}}},
  author = {Keogh, E. and Lin, J. and Fu, A.W. and Van Herle, H.},
  year = {2006},
  month = jul,
  volume = {10},
  pages = {429--439},
  issn = {1089-7771, 1558-0032},
  doi = {10.1109/TITB.2005.863870},
  abstract = {In this work, we introduce the new problem of finding time series discords. Time series discords are subsequences of longer time series that are maximally different to all the rest of the time series subsequences. They thus capture the sense of the most unusual subsequence within a time series. While discords have many uses for data mining, they are particularly attractive as anomaly detectors because they only require one intuitive parameter (the length of the subsequence), unlike most anomaly detection algorithms that typically require many parameters. While the brute force algorithm to discover time series discords is quadratic in the length of the time series, we show a simple algorithm that is three to four orders of magnitude faster than brute force, while guaranteed to produce identical results. We evaluate our work with a comprehensive set of experiments on electrocardiograms and other medical datasets.},
  file = {/home/moritz/Documents/thesis.git/papers/keogh2006.pdf},
  journal = {IEEE Transactions on Information Technology in Biomedicine},
  language = {en},
  number = {3}
}

@article{kligfield2007,
  ids = {kligfield2007a,kligfieldpaul2007},
  title = {Recommendations for the {{Standardization}} and {{Interpretation}} of the {{Electrocardiogram}}: {{Part I}}: {{The Electrocardiogram}} and {{Its Technology}}: {{A Scientific Statement From}} the {{American Heart Association Electrocardiography}} and {{Arrhythmias Committee}}, {{Council}} on {{Clinical Cardiology}}; the {{American College}} of {{Cardiology Foundation}}; and the {{Heart Rhythm Society}} {{{\emph{Endorsed}}}}{\emph{ by the }}{{{\emph{International Society}}}}{\emph{ for }}{{{\emph{Computerized Electrocardiology}}}}},
  shorttitle = {Recommendations for the {{Standardization}} and {{Interpretation}} of the {{Electrocardiogram}}},
  author = {Kligfield, Paul and Gettes, Leonard S. and Bailey, James J. and Childers, Rory and Deal, Barbara J. and Hancock, E. William and {van Herpen}, Gerard and Kors, Jan A. and Macfarlane, Peter and Mirvis, David M. and Pahlm, Olle and Rautaharju, Pentti and Wagner, Galen S.},
  year = {2007},
  month = mar,
  volume = {115},
  pages = {1306--1324},
  publisher = {{American Heart Association}},
  issn = {0009-7322, 1524-4539},
  doi = {10.1161/CIRCULATIONAHA.106.180200},
  file = {/home/moritz/Documents/thesis.git/papers/kligfield2007.pdf;/home/moritz/Zotero/storage/FBVW54N4/Kligfield Paul et al. - 2007 - Recommendations for the Standardization and Interp.pdf;/home/moritz/Zotero/storage/ETL9II6L/CIRCULATIONAHA.106.html},
  journal = {Circulation},
  language = {en},
  number = {10}
}

@article{kulahcioglu2021,
  title = {Application of {{Symbolic Piecewise Aggregate Approximation}} ({{PAA}}) {{Analysis}} to {{ECG Signals}}},
  author = {Kulahcioglu, Burcu and Ozdemir, Serhan and Kumova, Bora},
  year = {2021},
  month = mar,
  abstract = {Symbolic Time Series Analysis (STA) is an emerging methodology that involves coarse graining of the signals. Repeating segments of the time series are associated with symbols, thereby reducing the complexity of the series. It facilitates data mining tasks to be performed easily such as indexing, clustering, classification, summarization, and anomaly detection. This study involves symbolization through Symbolic Aggregate Approximation (SAX) with Piecewise Aggregate Approximation (PAA). The same ECG series is symbolized first by PLA and then PAA. Coarsing the series by PLA proved to be more problematic than PAA. At coarser scales, details are lost in noise with PLA, whereas local features become clearer with PAA. However during the analyses of ECGs of various subjects, it is understood that PAA fails when the series is not perfectly periodic as in rotating machinery. This fact is contrasted with the synthetic ECG which is manipulated to be perfectly periodic to juxtapose the results of the two trials. It is deduced that PAA delivers better pattern detection when signals are truly periodic.},
  file = {/home/moritz/Zotero/storage/NA6NM2AB/Kulahcioglu et al. - 2021 - Application of Symbolic Piecewise Aggregate Approx.pdf}
}

@inproceedings{laguna1997,
  title = {A Database for Evaluation of Algorithms for Measurement of {{QT}} and Other Waveform Intervals in the {{ECG}}},
  booktitle = {Computers in {{Cardiology}} 1997},
  author = {Laguna, P. and Mark, R.G. and Goldberg, A. and Moody, G.B.},
  year = {1997},
  pages = {673--676},
  publisher = {{IEEE}},
  address = {{Lund, Sweden}},
  doi = {10.1109/CIC.1997.648140},
  file = {/home/moritz/Documents/thesis.git/papers/laguna1997.pdf},
  isbn = {978-0-7803-4445-7},
  language = {en}
}

@inproceedings{lin2003,
  title = {A Symbolic Representation of Time Series, with Implications for Streaming Algorithms},
  booktitle = {Proceedings of the 8th {{ACM SIGMOD}} Workshop on {{Research}} Issues in Data Mining and Knowledge Discovery  - {{DMKD}} '03},
  author = {Lin, Jessica and Keogh, Eamonn and Lonardi, Stefano and Chiu, Bill},
  year = {2003},
  pages = {2--11},
  publisher = {{ACM Press}},
  address = {{San Diego, California}},
  doi = {10.1145/882082.882086},
  abstract = {The parallel explosions of interest in streaming data, and data mining of time series have had surprisingly little intersection. This is in spite of the fact that time series data are typically streaming data. The main reason for this apparent paradox is the fact that the vast majority of work on streaming data explicitly assumes that the data is discrete, whereas the vast majority of time series data is real valued.Many researchers have also considered transforming real valued time series into symbolic representations, nothing that such representations would potentially allow researchers to avail of the wealth of data structures and algorithms from the text processing and bioinformatics communities, in addition to allowing formerly "batch-only" problems to be tackled by the streaming community. While many symbolic representations of time series have been introduced over the past decades, they all suffer from three fatal flaws. Firstly, the dimensionality of the symbolic representation is the same as the original data, and virtually all data mining algorithms scale poorly with dimensionality. Secondly, although distance measures can be defined on the symbolic approaches, these distance measures have little correlation with distance measures defined on the original time series. Finally, most of these symbolic approaches require one to have access to all the data, before creating the symbolic representation. This last feature explicitly thwarts efforts to use the representations with streaming algorithms.In this work we introduce a new symbolic representation of time series. Our representation is unique in that it allows dimensionality/numerosity reduction, and it also allows distance measures to be defined on the symbolic approach that lower bound corresponding distance measures defined on the original series. As we shall demonstrate, this latter feature is particularly exciting because it allows one to run certain data mining algorithms on the efficiently manipulated symbolic representation, while producing identical results to the algorithms that operate on the original data. Finally, our representation allows the real valued data to be converted in a streaming fashion, with only an infinitesimal time and space overhead.We will demonstrate the utility of our representation on the classic data mining tasks of clustering, classification, query by content and anomaly detection.},
  file = {/home/moritz/Documents/thesis.git/papers/lin2003.pdf},
  language = {en}
}

@inproceedings{liu2018,
  ids = {liu2018a},
  title = {Classification of {{Heart Diseases Based On ECG Signals Using Long Short}}-{{Term Memory}}},
  booktitle = {2018 40th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  author = {Liu, M. and Kim, Y.},
  year = {2018},
  month = jul,
  pages = {2707--2710},
  issn = {1558-4615},
  doi = {10.1109/EMBC.2018.8512761},
  abstract = {Heart disease classification based on electrocardiogram(ECG) signal has become a priority topic in the diagnosis of heart diseases because it can be obtained with a simple diagnostic tool of low cost. Since early detection of heart disease can enable us to ease the treatment as well as save people's lives, accurate detection of heart disease using ECG is very important. In this paper, we propose a classification method of heart diseases based on ECG by adopting a machine learning method, called Long Short-Term Memory (LSTM), which is a state-of-the-art technique analyzing time series sequences in deep learning. As suitable data preprocessing, we also utilize symbolic aggregate approximation (SAX) to improve the accuracy. Our experiment results show that our approach not only achieves significantly better accuracy but also classifies heart diseases correctly in smaller response time than baseline techniques.},
  file = {/home/moritz/Zotero/storage/T6BYWC76/8512761.html},
  keywords = {Data preprocessing,deep learning,Deep Learning,diseases,Diseases,electrocardiogram signal,electrocardiography,Electrocardiography,Feature extraction,Heart,heart disease classification,Heart Diseases,Humans,learning (artificial intelligence),Long Short-Term Memory,machine learning method,medical signal processing,signal classification,state-of-the-art technique,symbolic aggregate approximation,Time factors,time series,time series sequences,Transforms}
}

@inproceedings{lkhagva2006,
  title = {Extended {{SAX}}: {{Extension}} of {{Symbolic Aggregate Approximation}} for {{Financial Time Series Data Representation}}},
  booktitle = {Proceeding of {{IEICE}} the 17th {{Data Engineering Workshop}}},
  author = {Lkhagva, Battuguldur and Suzuki, Yu and Kawagoe, Kyoji},
  year = {2006},
  pages = {7},
  address = {{Ginowan, Japan}},
  url = {https://www.researchgate.net/publication/229046404_Extended_SAX_extension_of_symbolic_aggregate_approximation_for_financial_time_series_data_representation},
  urldate = {2021-02-27},
  abstract = {Efficient and accurate similarity searching for a large amount of time series data set is an important but non-trivial problem. Many dimensionality reduction techniques have been proposed for effective representation of time series data in order to realize such similarity searching, including Singular Value Decomposition (SVD), the Discrete Fourier transform (DFT), the Adaptive Piecewise Constant Approximation (APCA), and the recently proposed Symbolic Aggregate Approximation (SAX).},
  file = {/home/moritz/Documents/thesis.git/papers/lkhagva2006.pdf},
  language = {en}
}

@inproceedings{malinowski2013,
  title = {1d-{{SAX}}: {{A Novel Symbolic Representation}} for {{Time Series}}},
  shorttitle = {1d-{{SAX}}},
  booktitle = {Advances in {{Intelligent Data Analysis XII}}},
  author = {Malinowski, Simon and Guyet, Thomas and Quiniou, Ren{\'e} and Tavenard, Romain},
  editor = {Tucker, Allan and H{\"o}ppner, Frank and Siebes, Arno and Swift, Stephen},
  year = {2013},
  pages = {273--284},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-41398-8_24},
  abstract = {SAX (Symbolic Aggregate approXimation) is one of the main symbolization techniques for time series. A well-known limitation of SAX is that trends are not taken into account in the symbolization. This paper proposes 1d-SAX a method to represent a time series as a sequence of symbols that each contain information about the average and the trend of the series on a segment. We compare the efficiency of SAX and 1d-SAX in terms of goodness-of-fit, retrieval and classification performance for querying a time series database with an asymmetric scheme. The results show that 1d-SAX improves performance using equal quantity of information, especially when the compression rate increases.},
  file = {/home/moritz/Zotero/storage/EQB5BMS4/Malinowski et al. - 2013 - 1d-SAX A Novel Symbolic Representation for Time S.pdf},
  isbn = {978-3-642-41398-8},
  keywords = {Average Approximation Error,Dynamic Time Warping Distance,Original Time Series,Symbolic Representation,Time Series},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@inproceedings{maniewski1997,
  ids = {maniewski1997a},
  title = {Time-Frequency Methods for High-Resolution {{ECG}} Analysis},
  booktitle = {Proceedings of 18th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}}},
  author = {Maniewski, R. and Lewandowski, P. and Nowinska, M. and Mroczka, T.},
  year = {1997},
  volume = {3},
  pages = {1266--1267},
  publisher = {{IEEE}},
  address = {{Amsterdam, Netherlands}},
  doi = {10.1109/IEMBS.1996.652804},
  file = {/home/moritz/Documents/thesis.git/papers/maniewski1997.pdf},
  isbn = {978-0-7803-3811-1},
  keywords = {comparison,ecg,overview},
  language = {en}
}

@article{meek2002,
  title = {Introduction. {{I}}\textemdash{{Leads}}, Rate, Rhythm, and Cardiac Axis},
  author = {Meek, Steve and Morris, Francis},
  year = {2002},
  month = feb,
  volume = {324},
  pages = {415--418},
  issn = {0959-8138},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1122339/},
  urldate = {2021-05-21},
  file = {/home/moritz/Zotero/storage/EV7S5FFG/Meek and Morris - 2002 - Introduction. ILeads, rate, rhythm, and cardiac a.pdf},
  journal = {BMJ : British Medical Journal},
  number = {7334},
  pmcid = {PMC1122339},
  pmid = {11850377}
}

@inproceedings{minnen2006,
  title = {Discovering {{Characteristic Actions}} from {{On}}-{{Body Sensor Data}}},
  booktitle = {2006 10th {{IEEE International Symposium}} on {{Wearable Computers}}},
  author = {Minnen, David and Starner, Thad and Essa, Irfan and Isbell, Charles},
  year = {2006},
  month = oct,
  pages = {11--18},
  publisher = {{IEEE}},
  address = {{Montreux, Switzerland}},
  issn = {1550-4816},
  doi = {10.1109/ISWC.2006.286337},
  abstract = {We present an approach to activity discovery, the unsupervised identification and modeling of human actions embedded in a larger sensor stream. Activity discovery can be seen as the inverse of the activity recognition problem. Rather than learn models from hand-labeled sequences, we attempt to discover motifs, sets of similar subsequences within the raw sensor stream, without the benefit of labels or manual segmentation. These motifs are statistically unlikely and thus typically correspond to important or characteristic actions within the activity.},
  file = {/home/moritz/Documents/thesis.git/papers/minnen2006.pdf},
  isbn = {978-1-4244-0597-8},
  language = {en}
}

@article{moody2001,
  title = {The Impact of the {{MIT}}-{{BIH Arrhythmia Database}}},
  author = {Moody, G.B. and Mark, R.G.},
  year = {May-June/2001},
  volume = {20},
  pages = {45--50},
  issn = {07395175},
  doi = {10.1109/51.932724},
  file = {/home/moritz/Documents/thesis.git/papers/moody2001.pdf},
  journal = {IEEE Engineering in Medicine and Biology Magazine},
  language = {en},
  number = {3}
}

@article{moskovitch2015,
  title = {Classification of Multivariate Time Series via Temporal Abstraction and Time Intervals Mining},
  author = {Moskovitch, Robert and Shahar, Yuval},
  year = {2015},
  month = oct,
  volume = {45},
  pages = {35--74},
  issn = {0219-3116},
  doi = {10.1007/s10115-014-0784-5},
  abstract = {Classification of multivariate time series data, often including both time points and intervals at variable frequencies, is a challenging task. We introduce the KarmaLegoSification (KLS) framework for classification of multivariate time series analysis, which implements three phases: (1) application of a temporal abstraction process that transforms a series of raw time-stamped data points into a series of symbolic time intervals; (2) mining these symbolic time intervals to discover frequent time-interval-related patterns (TIRPs), using Allen's temporal relations; and (3) using the TIRPs as features to induce a classifier. To efficiently detect multiple TIRPs (features) in a single entity to be classified, we introduce a new algorithm, SingleKarmaLego, which can be shown to be superior for that purpose over a Sequential TIRPs Detection algorithm. We evaluated the KLS framework on datasets in the domains of diabetes, intensive care, and infectious hepatitis, assessing the effects of the various settings of the KLS framework. Discretization using Symbolic Aggregate approXimation (SAX) led to better performance than using the equal-width discretization (EWD); knowledge-based cut-off definitions when available were superior to both. Using three abstract temporal relations was superior to using the seven core temporal relations. Using an epsilon value larger than zero tended to result in a slightly better accuracy when using the SAX discretization method, but resulted in a reduced accuracy when using EWD, and overall, does not seem beneficial. No feature selection method we tried proved useful. Regarding feature (TIRP) representation, mean duration performed better than horizontal support, which in turn performed better than the default Binary (existence) representation method.},
  file = {/home/moritz/Zotero/storage/TMPYEWGA/Moskovitch and Shahar - 2015 - Classification of multivariate time series via tem.pdf},
  journal = {Knowledge and Information Systems},
  language = {en},
  number = {1}
}

@article{nowbar2019,
  title = {Mortality {{From Ischemic Heart Disease}}: {{Analysis}} of {{Data From}} the {{World Health Organization}} and {{Coronary Artery Disease Risk Factors From NCD Risk Factor Collaboration}}},
  shorttitle = {Mortality {{From Ischemic Heart Disease}}},
  author = {Nowbar, Alexandra N. and Gitto, Mauro and Howard, James P. and Francis, Darrel P. and {Al-Lamee}, Rasha},
  year = {2019},
  month = jun,
  volume = {12},
  issn = {1941-7713, 1941-7705},
  doi = {10.1161/CIRCOUTCOMES.118.005375},
  abstract = {BACKGROUND: Ischemic heart disease (IHD) has been considered the top cause of mortality globally. However, countries differ in their rates and there have been changes over time. METHODS AND RESULTS: We analyzed mortality data submitted to the World Health Organization from 2005 to 2015 by individual countries. We explored patterns in relationships with age, sex, and income and calculated age-standardized mortality rates for each country in addition to crude death rates. In 5 illustrative countries which provided detailed data, we analyzed trends of mortality from IHD and 3 noncommunicable diseases (lung cancer, stroke, and chronic lower respiratory tract diseases) and examined the simultaneous trends in important cardiovascular risk factors. Russia, United States, and Ukraine had the largest absolute numbers of deaths among the countries that provided data. Among 5 illustrative countries (United Kingdom, United States, Brazil, Kazakhstan, and Ukraine), IHD was the top cause of death, but mortality from IHD has progressively decreased from 2005 to 2015. Age-standardized IHD mortality rates per 100\,000 people per year were much higher in Ukraine (324) and Kazakhstan (97) than in United States (60), Brazil (54), and the United Kingdom (46), with much less difference in other causes of death. All 5 countries showed a progressive decline in IHD mortality, with a decline in smoking and hypertension and in all cases a rise in obesity and type II diabetes mellitus. CONCLUSIONS: IHD remains the single largest cause of death in countries of all income groups. Rates are different between countries and are falling in most countries, indicating great potential for further gains. On the horizon, future improvements may become curtailed by increasing hypertension in some developing countries and more importantly global growth in obesity.},
  file = {/home/moritz/Documents/thesis.git/papers/nowbar2019.pdf},
  journal = {Circulation: Cardiovascular Quality and Outcomes},
  language = {en},
  number = {6}
}

@inproceedings{nygaard1998,
  title = {Compressing {{ECG}} Signals by Piecewise Polynomial Approximation},
  booktitle = {Proceedings of the 1998 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}}, {{ICASSP}} '98 ({{Cat}}. {{No}}.{{98CH36181}})},
  author = {Nygaard, R. and Haugland, D.},
  year = {1998},
  volume = {3},
  pages = {1809--1812},
  publisher = {{IEEE}},
  address = {{Seattle, WA, USA}},
  doi = {10.1109/ICASSP.1998.681812},
  abstract = {Compression of digital ElectroCardioGram (ECG) signals has traditionally been tackled by heuristical approaches. Recently, it has been demonstrated [1] that exact optimization algorithms outclass these heuristical approaches by a wide margin with respect to reconstruction error. As opposed to traditional time-domain algorithms, where some heuristic is used to extract representative signal samples from the original signal, the exact optimization algorithm in [1] formulates the sample selection problem as a graph theory problem. Thus well known optimization theory can be applied in order to yield optimal compression. In [1], linear interpolation is applied in reconstruction of the signal. This paper generalizes the optimization algorithm such that reconstruction can be made by second order polynomial interpolation in the extracted signal samples. The polynomials are fitted in a way that guarantees minimal reconstruction error, and the method proves good performance compared to the case where linear interpolation is used in reconstruction of the signal.},
  file = {/home/moritz/Zotero/storage/QA64KW6W/Nygaard and Haugland - 1998 - Compressing ECG signals by piecewise polynomial ap.pdf},
  isbn = {978-0-7803-4428-0},
  language = {en}
}

@article{ordonez2008,
  title = {Visualizing {{Multivariate Time Series Data}} to {{Detect Specific Medical Conditions}}},
  author = {Ord{\'o}{\~n}ez, Patricia and {desJardins}, Marie and Feltes, Carolyn and Lehmann, Christoph U. and Fackler, James},
  year = {2008},
  volume = {2008},
  pages = {530--534},
  issn = {1942-597X},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2656052/},
  urldate = {2021-03-30},
  abstract = {Efficient unsupervised algorithms for the detection of patterns in time series data, often called motifs, have been used in many applications, such as identifying words in different languages, detecting anomalies in ECG readings, and finding similarities between images. We present a process that creates a personalized multivariate time series representation\textemdash a Multivariate Time Series Amalgam (MTSA) \textemdash{} of physiological data and laboratory results that physicians can visually interpret. We then apply a technique that has demonstrated success with the interpretation of univariate data, named Symbolic Aggregate Approximation (SAX), to visualize patterns in the MTSAs that may differentiate between medical conditions such as renal and respiratory failure.},
  file = {/home/moritz/Zotero/storage/MQFAWGBC/Ordez et al. - 2008 - Visualizing Multivariate Time Series Data to Detec.pdf},
  journal = {AMIA Annual Symposium Proceedings},
  pmcid = {PMC2656052},
  pmid = {18999033}
}

@incollection{panuccio2002,
  title = {A {{Hidden Markov Model}}-{{Based Approach}} to {{Sequential Data Clustering}}},
  booktitle = {Structural, {{Syntactic}}, and {{Statistical Pattern Recognition}}},
  author = {Panuccio, Antonello and Bicego, Manuele and Murino, Vittorio},
  editor = {Goos, G. and Hartmanis, J. and {van Leeuwen}, J. and Caelli, Terry and Amin, Adnan and Duin, Robert P. W. and {de Ridder}, Dick and Kamel, Mohamed},
  year = {2002},
  volume = {2396},
  pages = {734--743},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/3-540-70659-3_77},
  abstract = {Clustering of sequential or temporal data is more challenging than traditional clustering as dynamic observations should be processed rather than static measures. This paper proposes a Hidden Markov Model (HMM)-based technique suitable for clustering of data sequences. The main aspect of the work is the use of a probabilistic model-based approach using HMM to derive new proximity distances, in the likelihood sense, between sequences. Moreover, a novel partitional clustering algorithm is designed which alleviates computational burden characterizing traditional hierarchical agglomerative approaches. Experimental results show that this approach provides an accurate clustering partition and the devised distance measures achieve good performance rates. The method is demonstrated on real world data sequences, i.e. the EEG signals due to their temporal complexity and the growing interest in the emerging field of Brain Computer Interfaces.},
  file = {/home/moritz/Documents/thesis.git/papers/panuccio2002.pdf},
  isbn = {978-3-540-44011-6 978-3-540-70659-5},
  language = {en}
}

@article{park2020,
  title = {{{SAX}}-{{ARM}}: {{Deviant}} Event Pattern Discovery from Multivariate Time Series Using Symbolic Aggregate Approximation and Association Rule Mining},
  shorttitle = {{{SAX}}-{{ARM}}},
  author = {Park, Hoonseok and Jung, Jae-Yoon},
  year = {2020},
  month = mar,
  volume = {141},
  pages = {112950},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2019.112950},
  abstract = {The discovery of event patterns from multivariate time series is important to academics and practitioners. In particular, we consider the event patterns related to anomalies such as outliers and deviations, which are important factors in system monitoring for manufacturing processes. In this paper, we propose a method for discovering the rules to describe deviant event patterns from multivariate time series, called SAX-ARM (association rule mining based on symbolic aggregate approximation). Inverse normal transformation (INT) is first adopted for converting the distribution of time series to the normal distribution. Then, symbolic aggregate approximation (SAX) is applied to symbolize time series, and association rule mining (ARM) is used for discovering frequent rules among the symbols of deviant events. The experimental results show the discovery of informative rules among deviant events in a multivariate time series from a die-casting manufacturing process that has ten variables with 1,437 lengths. We also present the results of sensitivity analysis, which demonstrates that significant rules can be discovered with different settings of the SAX parameters. The results describe the usefulness of the proposed method to identify deviant event among multivariate time series with high complexity.},
  file = {/home/moritz/Zotero/storage/4IY844C2/Park and Jung - 2020 - SAX-ARM Deviant event pattern discovery from mult.pdf;/home/moritz/Zotero/storage/W473NEMY/S0957417419306682.html},
  journal = {Expert Systems with Applications},
  keywords = {Association rule mining (ARM),Event pattern discovery,Inverse normal transformation (INT),Multivariate time series,Symbolic aggregate approximation (SAX)},
  language = {en}
}

@inproceedings{pham2010,
  title = {{{HOT aSAX}}: {{A Novel Adaptive Symbolic Representation}} for {{Time Series Discords Discovery}}},
  shorttitle = {{{HOT aSAX}}},
  booktitle = {Intelligent {{Information}} and {{Database Systems}}},
  author = {Pham, Ninh D. and Le, Quang Loc and Dang, Tran Khanh},
  editor = {Nguyen, Ngoc Thanh and Le, Manh Thanh and {\'S}wi{\k{a}}tek, Jerzy},
  year = {2010},
  pages = {113--121},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-12145-6_12},
  abstract = {Finding discords in time series database is an important problem in the last decade due to its variety of real-world applications, including data cleansing, fault diagnostics, and financial data analysis. The best known approach to our knowledge is HOT SAX technique based on the equiprobable distribution of SAX representations of time series. This characteristic, however, is not preserved in the reduced-dimensionality literature, especially on the lack of Gaussian distribution datasets. In this paper, we introduce a k-means based algorithm for symbolic representations of time series called adaptive Symbolic Aggregate approXimation (aSAX) and propose HOT aSAX algorithm for time series discords discovery. Due to the clustered characteristic of aSAX words, our algorithm produces greater pruning power than the previous approach. Our empirical experiments with real-world time series datasets confirm the theoretical analyses as well as the efficiency of our approach.},
  file = {/home/moritz/Zotero/storage/8C8W37CT/Pham et al. - 2010 - HOT aSAX A Novel Adaptive Symbolic Representation.pdf},
  isbn = {978-3-642-12145-6},
  keywords = {Anomaly Detection,Clustering,SAX,Time Series Data Mining},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{prasad2018,
  ids = {prasad2018a},
  title = {Detection and Classification of Cardiovascular Abnormalities Using {{FFT}} Based Multi-Objective Genetic Algorithm},
  author = {Prasad, B. V. P and Parthasarathy, Velusamy},
  year = {2018},
  month = jan,
  volume = {32},
  pages = {183--193},
  issn = {1310-2818, 1314-3530},
  doi = {10.1080/13102818.2017.1389303},
  abstract = {Signal processing and data analysis are widely used methods in a biomedical research. In recent years, detection of cardiovascular abnormalities in patients can be achieved by using electrocardiogram (ECG) recording. In this paper, a fuzzy-based multi-objective algorithm using Fast Fourier Transform (FFT) is proposed. Initially, an effective FFT is used to extract the feature points in ECG signals, such as PQRST wave's amplitude and wave function and then the proposed multi-objective genetic algorithm is used to classify the abnormality of heart patient. Basically, the ECG behaviour depends on various factors such as age, physical condition of patients and the surrounding environment. The efficient detection of abnormalities (e.g. arrhythmia and myocardial abstraction) can be achieved by initializing the above-mentioned factors and maintaining a database containing previously attributed signals, such MIT-BIH arrhythmia. The present study provides efficiency of around 98.7\% in detection of abnormalities in patients.},
  file = {/home/moritz/Documents/thesis.git/papers/prasad2018.pdf;/home/moritz/Documents/thesis.git/papers/prasad2018.pdf},
  journal = {Biotechnology \& Biotechnological Equipment},
  language = {en},
  number = {1}
}

@inproceedings{ratanamahatana2005,
  title = {A {{Novel Bit Level Time Series Representation}} with {{Implication}} of {{Similarity Search}} and {{Clustering}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ratanamahatana, Chotirat and Keogh, Eamonn and Bagnall, Anthony J. and Lonardi, Stefano},
  editor = {Ho, Tu Bao and Cheung, David and Liu, Huan},
  year = {2005},
  pages = {771--777},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/11430919_90},
  abstract = {Because time series are a ubiquitous and increasingly prevalent type of data, there has been much research effort devoted to time series data mining recently. As with all data mining problems, the key to effective and scalable algorithms is choosing the right representation of the data. Many high level representations of time series have been proposed for data mining. In this work, we introduce a new technique based on a bit level approximation of the data. The representation has several important advantages over existing techniques. One unique advantage is that it allows raw data to be directly compared to the reduced representation, while still guaranteeing lower bounds to Euclidean distance. This fact can be exploited to produce faster exact algorithms for similarly search. In addition, we demonstrate that our new representation allows time series clustering to scale to much larger datasets.},
  file = {/home/moritz/Zotero/storage/7S39X27N/Ratanamahatana et al. - 2005 - A Novel Bit Level Time Series Representation with .pdf},
  isbn = {978-3-540-31935-1},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{senin,
  title = {{{SAX}}-{{VSM}}: {{Interpretable Time Series Classification Using SAX}} and {{Vector Space Model}}},
  author = {Senin, Pavel and Malinchik, Sergey},
  pages = {11},
  abstract = {In this paper, we propose a novel method for characteristic patterns discovery in time series. This method, called SAX-VSM, is based on two existing techniques - Symbolic Aggregate approXimation and Vector Space Model. SAX-VSM is capable to automatically discover and rank time series patterns by their importance to the class, which not only creates wellperforming classifiers and facilitates clustering, but also provides an interpretable class generalization. The accuracy of the method, as shown through experimental evaluation, is at the level of the current state of the art. While being relatively computationally expensive within a learning phase, our method provides fast, precise, and interpretable classification.},
  file = {/home/moritz/Zotero/storage/V8246E43/SAX-VSM Interpretable Time Series Classification .pdf},
  language = {en}
}

@inproceedings{shieh2008,
  title = {{\emph{I}} {{SAX}}: Indexing and Mining Terabyte Sized Time Series},
  shorttitle = {{\emph{I}} {{SAX}}},
  booktitle = {Proceeding of the 14th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining - {{KDD}} 08},
  author = {Shieh, Jin and Keogh, Eamonn},
  year = {2008},
  pages = {623},
  publisher = {{ACM Press}},
  address = {{Las Vegas, Nevada, USA}},
  doi = {10.1145/1401890.1401966},
  abstract = {Current research in indexing and mining time series data has produced many interesting algorithms and representations. However, the algorithms and the size of data considered have generally not been representative of the increasingly massive datasets encountered in science, engineering, and business domains. In this work, we show how a novel multi-resolution symbolic representation can be used to index datasets which are several orders of magnitude larger than anything else considered in the literature. Our approach allows both fast exact search and ultra fast approximate search. We show how to exploit the combination of both types of search as sub-routines in data mining algorithms, allowing for the exact mining of truly massive real world datasets, containing millions of time series.},
  file = {/home/moritz/Documents/thesis.git/papers/shieh2008.pdf},
  isbn = {978-1-60558-193-4},
  language = {en}
}

@article{sivaraks2015,
  title = {Robust and {{Accurate Anomaly Detection}} in {{ECG Artifacts Using Time Series Motif Discovery}}},
  author = {Sivaraks, Haemwaan and Ratanamahatana, Chotirat Ann},
  year = {2015},
  volume = {2015},
  pages = {1--20},
  issn = {1748-670X, 1748-6718},
  doi = {10.1155/2015/453214},
  abstract = {Electrocardiogram (ECG) anomaly detection is an important technique for detecting dissimilar heartbeats which helps identify abnormal ECGs before the diagnosis process. Currently available ECG anomaly detection methods, ranging from academic research to commercial ECG machines, still suffer from a high false alarm rate because these methods are not able to differentiate ECG artifacts from real ECG signal, especially, in ECG artifacts that are similar to ECG signals in terms of shape and/or frequency. The problem leads to high vigilance for physicians and misinterpretation risk for nonspecialists. Therefore, this work proposes a novel anomaly detection technique that is highly robust and accurate in the presence of ECG artifacts which can effectively reduce the false alarm rate. Expert knowledge from cardiologists and motif discovery technique is utilized in our design. In addition, every step of the algorithm conforms to the interpretation of cardiologists. Our method can be utilized to both single-lead ECGs and multilead ECGs. Our experiment results on real ECG datasets are interpreted and evaluated by cardiologists. Our proposed algorithm can mostly achieve 100\% of accuracy on detection (AoD), sensitivity, specificity, and positive predictive value with 0\% false alarm rate. The results demonstrate that our proposed method is highly accurate and robust to artifacts, compared with competitive anomaly detection methods.},
  file = {/home/moritz/Documents/thesis.git/papers/sivaraks2015.pdf},
  journal = {Computational and Mathematical Methods in Medicine},
  language = {en}
}

@article{song2020b,
  ids = {song2020a},
  title = {Transitional {{SAX Representation}} for {{Knowledge Discovery}} for {{Time Series}}},
  author = {Song, Kiburm and Ryu, Minho and Lee, Kichun},
  year = {2020},
  month = oct,
  volume = {10},
  pages = {6980},
  publisher = {{MDPI AG}},
  issn = {2076-3417},
  doi = {10.3390/app10196980},
  abstract = {DOAJ is a community-curated online directory that indexes and provides access to high quality, open access, peer-reviewed journals.},
  file = {/home/moritz/Zotero/storage/QCGKMW77/Song et al. - 2020 - Transitional SAX Representation for Knowledge Disc.pdf;C\:\\Users\\morit\\Downloads\\applsci-10-06980-v3 (1).pdf;/home/moritz/Zotero/storage/A3SQQUDQ/943c3aa4284841959a1adb9ce6315c56.html},
  journal = {Applied Sciences},
  language = {en},
  number = {6980}
}

@article{sun2014,
  ids = {sun2014a},
  title = {An Improvement of Symbolic Aggregate Approximation Distance Measure for Time Series},
  author = {Sun, Youqiang and Li, Jiuyong and Liu, Jixue and Sun, Bingyu and Chow, Christopher},
  year = {2014},
  month = aug,
  volume = {138},
  pages = {189--198},
  issn = {09252312},
  doi = {10.1016/j.neucom.2014.01.045},
  abstract = {Symbolic Aggregate approXimation (SAX) as a major symbolic representation has been widely used in many time series data mining applications. However, because a symbol is mapped from the average value of a segment, the SAX ignores important information in a segment, namely the trend of the value change in the segment. Such a miss may cause a wrong classification in some cases, since the SAX representation cannot distinguish different time series with similar average values but different trends. In this paper, we firstly design a measure to compute the distance of trends using the starting and the ending points of segments. Then we propose a modified distance measure by integrating the SAX distance with a weighted trend distance. We show that our distance measure has a tighter lower bound to the Euclidean distance than that of the original SAX. The experimental results on diverse time series data sets demonstrate that our proposed representation significantly outperforms the original SAX representation and an improved SAX representation for classification.},
  file = {/home/moritz/Documents/thesis.git/papers/sun2014.pdf;/home/moritz/Zotero/storage/9UUDIKCJ/S0925231214002872.html},
  journal = {Neurocomputing},
  keywords = {Classification,Lower bound,Symbolic Aggregate approXimation,Time series,Trend distance},
  language = {en}
}

@article{taddei1992,
  title = {The {{European ST}}-{{T}} Database: Standard for Evaluating Systems for the Analysis of {{ST}}-{{T}} Changes in Ambulatory Electrocardiography},
  shorttitle = {The {{European ST}}-{{T}} Database},
  author = {Taddei, A. and Distante, G. and Emdin, M. and Pisani, P. and Moody, G. B. and Zeelenberg, C. and Marchesi, C.},
  year = {1992},
  month = sep,
  volume = {13},
  pages = {1164--1172},
  issn = {1522-9645, 0195-668X},
  doi = {10.1093/oxfordjournals.eurheartj.a060332},
  file = {/home/moritz/Documents/thesis.git/papers/taddei1992.pdf},
  journal = {European Heart Journal},
  language = {en},
  number = {9}
}

@inproceedings{tamura2017,
  title = {Clustering of Time Series Using Hybrid Symbolic Aggregate Approximation},
  booktitle = {2017 {{IEEE Symposium Series}} on {{Computational Intelligence}} ({{SSCI}})},
  author = {Tamura, K. and Ichimura, T.},
  year = {2017},
  month = nov,
  pages = {1--8},
  doi = {10.1109/SSCI.2017.8280846},
  abstract = {Clustering of time series is one of the best-known grand challenges in time series analysis because of its application potentialities and difficulty. It is like data clustering and the task of partitioning time series into several groups based on their similarities, such that time series in a cluster are similar and they are not similar to other clusters. In the last decade, symbolic aggregate approximation (SAX), which is a high-level symbolic representation for time series, has attracted the attention of many data mining researchers. SAX enables time series analysis to be applied to sequence mining techniques. In this study, we propose a new approach for clustering time series that utilizes a moving average convergence divergence (MACD)-histogram-based SAX (MHSAX) and the k-medoids method. MHSAX is a hybrid symbolic aggregate approximation combining the SAX strings of a time series and its MACD histogram. By utilizing MHSAX, we can calculate the more accurate distance between time series compared with other approaches. This improves the affinity with the k-medoids method and improves the accuracy of clustering. We actually implemented the proposed clustering method and conducted experiments using the whole UCR Time Series Archive data sets. The experimental results show that the proposed method is superior to other state-of-the-art methods.},
  keywords = {Aggregates,Clustering,Clustering methods,Feature extraction,Hidden Markov models,Histograms,k-medoids,MACD Histogram,SAX,Time measurement,Time series,Time series analysis}
}

@inproceedings{tayebi2011,
  title = {{{RA}}-{{SAX}}: {{Resource}}-{{Aware Symbolic Aggregate Approximation}} for {{Mobile ECG Analysis}}},
  shorttitle = {{{RA}}-{{SAX}}},
  booktitle = {2011 {{IEEE}} 12th {{International Conference}} on {{Mobile Data Management}}},
  author = {Tayebi, H. and Krishnaswamy, S. and Waluyo, A. B. and Sinha, A. and Gaber, M. M.},
  year = {2011},
  month = jun,
  volume = {1},
  pages = {289--290},
  issn = {2375-0324},
  doi = {10.1109/MDM.2011.67},
  abstract = {There is a growing focus on 24/7 cardiac monitoring that leverages state of the art mobile phones and commercial-off-the-shelf (COTS) wearable bio-sensors. While many signal processing techniques for mobile ECG analysis have been developed, these techniques tend to be computationally intensive. In this paper, we propose, develop and evaluate a resource-aware and energy-efficient time series analysis technique for real-time ECG analysis on mobile devices based on the well-known SAX (Symbolic Aggregate Approximation) representation for time series termed RA-SAX.},
  file = {/home/moritz/Zotero/storage/KXPWSVDN/Tayebi et al. - 2011 - RA-SAX Resource-Aware Symbolic Aggregate Approxim.pdf;/home/moritz/Zotero/storage/2GLGVLKG/6068450.html},
  keywords = {Accuracy,approximation theory,biosensors,cardiac monitoring,Classification algorithms,Clustering algorithms,commercial-off-the-shelf,COTS,ECG,electrocardiography,Electrocardiography,medical signal processing,Mobile communication,mobile computing,Mobile Devices,mobile ECG analysis,mobile handsets,mobile phones,RA-SAX,resource aware symbolic aggregate approximation,signal processing techniques,Smart phones,symbolic aggregate approximation,Time Series}
}

@article{tseng2020,
  title = {Clustering {{Analysis}} of {{Aging Diseases}} and {{Chronic Habits With Multivariate Time Series Electrocardiogram}} and {{Medical Records}}},
  author = {Tseng, Kuo-Kun and Li, Jiaqian and Tang, Yih-Jing and Yang, Ching-Wen and Lin, Fang-Ying and Zhao, Zhaowen},
  year = {2020},
  volume = {12},
  publisher = {{Frontiers}},
  issn = {1663-4365},
  doi = {10.3389/fnagi.2020.00095},
  abstract = {Background: With recent technology, multivariate time series electrocardiogram (ECG) analysis has played an important role in diagnosing cardiovascular diseases. However, discovering the association of wide range aging disease and chronic habit with ECG analysis still has room to be explored. This paper mainly analyses the possible relationship between common aging diseases or chorionic habits of Medical Record and ECG, such as the diseases of diabetes, obesity and hypertension, or the habit of smoking. Whether there is a relationship between ECG and some common diseases and habits. Method: In the research, we firstly conducted different ECG features, such as those of reduced binary pattern (RBP), waveform, and wavelet, and then performed a k-means clustering analysis on the correlation between ECGs and the aforementioned diseases and habits, from which expected to find a firm association between them and the best characteristic used for future research. Result: In a summary, we discovered a weak and strong evidence between ECG and medical records, for the weak that the smokers might have a unique ECG feature vector enabling clustering them into specific groups, so the ECGs might be used to identify smokers and non-smokers. For a stronger evidence, most of patients with diabetes are always assigned into a specified group no matter of the number of classes in the K-means clustering, which means we can find their association between them. It is also interesting, we found that obesity and hypertension, which are thought to be related to cardiovascular system. However, they are not highly correlated in our clustering analysis, which might indirectly tell us that the impact of obesity and hypertension to our body is various.},
  file = {/home/moritz/Zotero/storage/SP9SHC7Z/Tseng et al. - 2020 - Clustering Analysis of Aging Diseases and Chronic .pdf},
  journal = {Frontiers in Aging Neuroscience},
  keywords = {Disease analysis,electrocardiogram,feature extraction,habit analysis,K-Means clustering},
  language = {English}
}

@inproceedings{valupadasu2012,
  ids = {valupadasu2012a},
  title = {Identification of {{Cardiac Ischemia Using Spectral Domain Analysis}} of {{Electrocardiogram}}},
  booktitle = {2012 {{UKSim}} 14th {{International Conference}} on {{Computer Modelling}} and {{Simulation}}},
  author = {Valupadasu, Rama and Chunduri, B. Rama Rao},
  year = {2012},
  month = mar,
  pages = {92--96},
  publisher = {{IEEE}},
  address = {{Cambridge, United Kingdom}},
  doi = {10.1109/UKSim.2012.22},
  file = {/home/moritz/Documents/thesis.git/papers/valupadasu2012.pdf},
  isbn = {978-1-4673-1366-7 978-0-7695-4682-7},
  language = {en}
}

@article{wang2010,
  title = {A Tree-Construction Search Approach for Multivariate Time Series Motifs Discovery},
  author = {Wang, L. and Chng, E.s. and Li, H.},
  year = {2010},
  month = jul,
  volume = {31},
  pages = {869--875},
  issn = {01678655},
  doi = {10.1016/j.patrec.2010.01.005},
  abstract = {Abstract: This paper examines an unsupervised search method to discover motifs from multivariate time series data. Our method first scans the entire series to construct a list of candidate motifs in linear time, the list is then used to populate a sparse self-similarity matrix for further processing to generate the final selections. The proposed algorithm is efficient in both running time and memory storage. To demonstrate its effectiveness, we applied it to search for repeating segments in both music and sensory data sets. The experimental results showed that the proposed method can efficiently detect repeating segments as compared to well-known methods such as self-similarity matrix search and symbolic aggregation approximation approaches.},
  journal = {Pattern Recognition Letters},
  keywords = {APPROXIMATION theory,Information retrieval,INFORMATION retrieval,MATRICES,Motif discovery,Multidimensional sequences,MULTIVARIATE analysis,Music,PATTERN perception,Pattern recognition,SEARCH algorithms,TIME series analysis,TREE graphs},
  number = {9}
}

@article{wang2016,
  ids = {wang2016a},
  title = {Representation {{Learning}} with {{Deconvolution}} for {{Multivariate Time Series Classification}} and {{Visualization}}},
  author = {Wang, Zhiguang and Song, Wei and Liu, Lu and Zhang, Fan and Xue, Junxiao and Ye, Yangdong and Fan, Ming and Xu, Mingliang},
  year = {2016},
  month = nov,
  url = {http://arxiv.org/abs/1610.07258},
  urldate = {2021-03-30},
  abstract = {We propose a new model based on the deconvolutional networks and SAX discretization to learn the representation for multivariate time series. Deconvolutional networks fully exploit the advantage the powerful expressiveness of deep neural networks in the manner of unsupervised learning. We design a network structure specifically to capture the cross-channel correlation with deconvolution, forcing the pooling operation to perform the dimension reduction along each position in the individual channel. Discretization based on Symbolic Aggregate Approximation is applied on the feature vectors to further extract the bag of features. We show how this representation and bag of features helps on classification. A full comparison with the sequence distance based approach is provided to demonstrate the effectiveness of our approach on the standard datasets. We further build the Markov matrix from the discretized representation from the deconvolution to visualize the time series as complex networks, which show more class-specific statistical properties and clear structures with respect to different labels.},
  archiveprefix = {arXiv},
  eprint = {1610.07258},
  eprinttype = {arxiv},
  file = {/home/moritz/Zotero/storage/6AH8PFEY/Wang et al. - 2016 - Representation Learning with Deconvolution for Mul.pdf;/home/moritz/Zotero/storage/M6V5WZ3P/Wang et al. - 2016 - Representation Learning with Deconvolution for Mul.pdf;/home/moritz/Zotero/storage/ZSWAQHQ2/1610.html},
  journal = {arXiv:1610.07258 [cs]},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing},
  primaryclass = {cs}
}

@article{warrenliao2005,
  title = {Clustering of Time Series Data\textemdash a Survey},
  author = {Warren Liao, T.},
  year = {2005},
  month = nov,
  volume = {38},
  pages = {1857--1874},
  issn = {00313203},
  doi = {10.1016/j.patcog.2005.01.025},
  abstract = {Time series clustering has been shown effective in providing useful information in various domains. There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains. The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research.},
  file = {/home/moritz/Documents/thesis.git/papers/warrenliao2005.pdf},
  journal = {Pattern Recognition},
  language = {en},
  number = {11}
}

@incollection{wasilewski2012,
  ids = {wasilewski2012a},
  title = {An {{Introduction}} to {{ECG Interpretation}}},
  booktitle = {{{ECG Signal Processing}}, {{Classification}} and {{Interpretation}}},
  author = {Wasilewski, Jaros{\l}aw and Polo{\'n}ski, Lech},
  editor = {Gacek, Adam and Pedrycz, Witold},
  year = {2012},
  pages = {1--20},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/978-0-85729-868-3_1},
  file = {/home/moritz/Documents/thesis.git/papers/wasilewski2012.pdf},
  isbn = {978-0-85729-867-6 978-0-85729-868-3},
  keywords = {Accessory Conduction Pathway,Electrical Axis,Left Ventricular Lead,Ventricular Depolarization,Ventricular Lead},
  language = {en}
}

@article{xie2020,
  ids = {xie2020a},
  title = {Computational {{Diagnostic Techniques}} for {{Electrocardiogram Signal Analysis}}},
  author = {Xie, Liping and Li, Zilong and Zhou, Yihan and He, Yiliu and Zhu, Jiaxin},
  year = {2020},
  month = nov,
  volume = {20},
  pages = {6318},
  issn = {1424-8220},
  doi = {10.3390/s20216318},
  abstract = {Cardiovascular diseases (CVDs), including asymptomatic myocardial ischemia, angina, myocardial infarction, and ischemic heart failure, are the leading cause of death globally. Early detection and treatment of CVDs significantly contribute to the prevention or delay of cardiovascular death. Electrocardiogram (ECG) records the electrical impulses generated by heart muscles, which reflect regular or irregular beating activity. Computer-aided techniques provide fast and accurate tools to identify CVDs using a patient's ECG signal, which have achieved great success in recent years. Latest computational diagnostic techniques based on ECG signals for estimating CVDs conditions are summarized here. The procedure of ECG signals analysis is discussed in several subsections, including data preprocessing, feature engineering, classification, and application. In particular, the End-to-End models integrate feature extraction and classification into learning algorithms, which not only greatly simplifies the process of data analysis, but also shows excellent accuracy and robustness. Portable devices enable users to monitor their cardiovascular status at any time, bringing new scenarios as well as challenges to the application of ECG algorithms. Computational diagnostic techniques for ECG signal analysis show great potential for helping health care professionals, and their application in daily life benefits both patients and sub-healthy people.},
  file = {/home/moritz/Documents/thesis.git/papers/xie2020.pdf},
  journal = {Sensors},
  language = {en},
  number = {21}
}

@article{yu2019,
  title = {A {{Novel Trend Symbolic Aggregate Approximation}} for {{Time Series}}},
  author = {Yu, Yufeng and Zhu, Yuelong and Wan, Dingsheng and Zhao, Qun and Liu, Huan},
  year = {2019},
  volume = {abs/1905.00421},
  pages = {9},
  url = {http://arxiv.org/abs/1905.00421},
  abstract = {Symbolic Aggregate approximation (SAX) is a classical symbolic approach in many time series data mining applications. However, SAX only reflects the segment mean value feature and misses important information in a segment, namely the trend of the value change in the segment. Such a miss may cause a wrong classification in some cases, since the SAX representation cannot distinguish different time series with similar average values but different trends. In this paper, we present Trend Feature Symbolic Aggregate approximation (TFSAX) to solve this problem. First, we utilize Piecewise Aggregate Approximation (PAA) approach to reduce dimensionality and discretize the mean value of each segment by SAX. Second, extract trend feature in each segment by using trend distance factor and trend shape factor. Then, design multi-resolution symbolic mapping rules to discretize trend information into symbols. We also propose a modified distance measure by integrating the SAX distance with a weighted trend distance. We show that our distance measure has a tighter lower bound to the Euclidean distance than that of the original SAX. The experimental results on diverse time series data sets demonstrate that our proposed representation significantly outperforms the original SAX representation and an improved SAX representation for classification.},
  file = {/home/moritz/Documents/thesis.git/papers/yu2019.pdf},
  language = {en}
}

@inproceedings{yu2019a,
  title = {A {{Novel Symbolic Aggregate Approximation}} for {{Time Series}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Ubiquitous Information Management}} and {{Communication}} ({{IMCOM}}) 2019},
  author = {Yu, Yufeng and Zhu, Yuelong and Wan, Dingsheng and Liu, Huan and Zhao, Qun},
  editor = {Lee, Sukhan and Ismail, Roslan and Choo, Hyunseung},
  year = {2019},
  pages = {805--822},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-19063-7_65},
  abstract = {Symbolic Aggregate approximation (SAX) is a classical symbolic approach in many time series data mining applications. However, SAX only reflects the segment mean value feature and misses important information in a segment, namely the trend of the value change in the segment. Such a miss may cause a wrong classification in some cases, since the SAX representation cannot distinguish different time series with similar average values but different trends. In this paper, we present Trend Feature Symbolic Aggregate approximation (TFSAX) to solve this problem. First, we utilize Piecewise Aggregate Approximation (PAA) approach to reduce dimensionality and discretize the mean value of each segment by SAX. Second, extract trend feature in each segment by using trend distance factor and trend shape factor. Then, design multi-resolution symbolic mapping rules to discretize trend information into symbols. We also propose a modified distance measure by integrating the SAX distance with a weighted trend distance. We show that our distance measure has a tighter lower bound to the Euclidean distance than that of the original SAX. The experimental results on diverse time series data sets demonstrate that our proposed representation significantly outperforms the original SAX representation and an improved SAX representation for classification.},
  isbn = {978-3-030-19063-7},
  keywords = {Distance measure,Lower bound,Symbolic aggregate approximation,Time series,Trend feature},
  language = {en},
  series = {Advances in {{Intelligent Systems}} and {{Computing}}}
}

@inproceedings{zan2016,
  title = {An Improved Symbolic Aggregate Approximation Distance Measure Based on Its Statistical Features},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Information Integration}} and {{Web}}-Based {{Applications}} and {{Services}}},
  author = {Zan, Chaw Thet and Yamana, Hayato},
  year = {2016},
  month = nov,
  pages = {72--80},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3011141.3011146},
  abstract = {The challenges in efficient data representation and similarity measures on massive amounts of time series have enormous impact on many applications. This paper addresses an improvement on Symbolic Aggregate approXimation (SAX), is one of the efficient representations for time series mining. Because SAX represents its symbols by the average (mean) value of a segment with the assumption of Gaussian distribution, it is insufficient to serve the entire deterministic information and causes sometimes incorrect results in time series classification. In this work, SAX representation and distance measure is improved with the addition of another moment of the prior distribution, standard deviation; SAX\_SD is proposed. We provide comprehensive analysis for the proposed SAX\_SD and confirm both the highest classification accuracy and the highest dimensionality reduction ratio on University of California, Riverside (UCR) datasets in comparison to state of the art methods such as SAX, Extended SAX (ESAX) and SAX Trend Distance (SAX\_TD).},
  file = {/home/moritz/Zotero/storage/FGQXNWHP/Zan and Yamana - 2016 - An improved symbolic aggregate approximation dista.pdf},
  isbn = {978-1-4503-4807-2},
  keywords = {classification,dimension reduction,statistical features,symbolic representation,time series},
  series = {{{iiWAS}} '16}
}

@article{zhang2019,
  title = {Anomaly Detection in {{ECG}} Based on Trend Symbolic Aggregate Approximation},
  author = {Zhang, Chunkai and Chen, Yingyang and Yin, Ao and Wang, Xuan and {Department of Computer Science and Technology, Harbin Institute of Technology, Shenzhen, China}},
  year = {2019},
  volume = {16},
  pages = {2154--2167},
  issn = {1547-1063},
  doi = {10.3934/mbe.2019105},
  abstract = {ECG anomaly detection is a necessary approach to detect disease Electrocardiography(ECG) signals before the detail diagnosis process in medical field to gauge the health of the human heart. Nowadays, there are many anomaly detection methods for ECG detection including supervised learning and unsupervised learning. For supervised learning, it requires the knowledge of expert and different types of Arrhythmia data for training. However, since the anomalies are less and unknown in many cases which are difficult to distinguish and be labeled, unsupervised methods are more suitable to detect the ECG anomalies. Furthermore, the existing unsupervised learning studies do not take ECG shape into account where different diseases have different shapes. In this paper, a novel simple trend aggregate approximation method is proposed, the relative binary trend representation are used to record the shape feature in original time series and to detect the anomaly heart signals by similarity comparison. We use the ECG dataset in UCR Time Series Classification Archive to obtain ECG time series data and the experiment results are assessed by means of sensitivity, specificity, false alarm rate measures which is robust and promising with high accuracy.},
  file = {/home/moritz/Documents/thesis.git/papers/zhang2019.pdf},
  journal = {Mathematical Biosciences and Engineering},
  keywords = {applied,ecg,method},
  language = {en},
  number = {4}
}

@article{zhang2019a,
  title = {A New Feature Extraction Approach Using Improved Symbolic Aggregate Approximation for Machinery Intelligent Diagnosis},
  author = {Zhang, Yulong and Duan, Lixiang and Duan, Menglan},
  year = {2019},
  month = feb,
  volume = {133},
  pages = {468--478},
  issn = {0263-2241},
  doi = {10.1016/j.measurement.2018.10.045},
  abstract = {Feature extraction from vibration signals is considerably significant for condition monitoring and fault diagnosis. The Symbolic Aggregate approXimation (SAX) technique essentially transforming a real-valued time series into a symbol sequence, has been proven as a potential tool of feature extraction for machinery intelligent diagnosis. However, challenge still exists that the SAX cannot fulfill feature extraction tasks well since it is carried out only on the basis of mean value in time domain. To overcome this limitation, an improved SAX (ISAX) is proposed in this paper. This new method substitutes the feature of mean value in time domain with multiple features extracted from time, frequency and time-frequency domains in order to obtain comprehensive fault information. With the ISAX transformation, a vibration signal can be transformed into various symbol sequences according to the multi-domain features. Next the Shannon entropy technique is conducted on a symbol sequence to capture sequential patterns in local signals and then the Shannon entropy value is used as the eigenvalue of the symbol sequence. Various eigenvalues are obtained to describe a vibration signal from different perspectives, which leads to a better feature extraction. These eigenvalues are then fed into the Kernel Principal Component Analysis (KPCA) to reduce dimensions and extract principal features for classification tasks. Compared with SAX, the most significant advantage of ISAX is extracting comprehensive signal characteristics from multi-domain. Moreover, the ISAX captures fault information better considering the local fault patterns. The effectiveness and superiority of ISAX were validated by experimental studies using the fault signals of rolling bearings and reciprocating compressor valves with remarkably high classification rates.},
  file = {/home/moritz/Zotero/storage/YJSZ5DNI/Zhang et al. - 2019 - A new feature extraction approach using improved s.pdf},
  journal = {Measurement},
  keywords = {Bearing defect diagnosis,Fault pattern,Improved SAX,Reciprocating compressor valve,Symbolic Aggregate approXimation (SAX)},
  language = {en}
}

@article{zheng2020,
  title = {A 12-Lead Electrocardiogram Database for Arrhythmia Research Covering More than 10,000 Patients},
  author = {Zheng, Jianwei and Zhang, Jianming and Danioko, Sidy and Yao, Hai and Guo, Hangyuan and Rakovski, Cyril},
  year = {2020},
  month = feb,
  volume = {7},
  pages = {48},
  publisher = {{Nature Publishing Group}},
  issn = {2052-4463},
  doi = {10.1038/s41597-020-0386-x},
  abstract = {This newly inaugurated research database for 12-lead electrocardiogram signals was created under the auspices of Chapman University and Shaoxing People's Hospital (Shaoxing Hospital Zhejiang University School of Medicine) and aims to enable the scientific community in conducting new studies on arrhythmia and other cardiovascular conditions. Certain types of arrhythmias, such as atrial fibrillation, have a pronounced negative impact on public health, quality of life, and medical expenditures. As a non-invasive test, long term ECG monitoring is a major and vital diagnostic tool for detecting these conditions. This practice, however, generates large amounts of data, the analysis of which requires considerable time and effort by human experts. Advancement of modern machine learning and statistical tools can be trained on high quality, large data to achieve exceptional levels of automated diagnostic accuracy. Thus, we collected and disseminated this novel database that contains 12-lead ECGs of 10,646 patients with a 500\,Hz sampling rate that features 11 common rhythms and 67 additional cardiovascular conditions, all labeled by professional experts. The dataset consists of 10-second, 12-dimension ECGs and labels for rhythms and other conditions for each subject. The dataset can be used to design, compare, and fine-tune new and classical statistical and machine learning techniques in studies focused on arrhythmia and other cardiovascular conditions.},
  copyright = {2020 The Author(s)},
  file = {/home/moritz/Zotero/storage/NC36QFPJ/Zheng et al. - 2020 - A 12-lead electrocardiogram database for arrhythmi.pdf;/home/moritz/Zotero/storage/YJXPEPE8/s41597-020-0386-x.html},
  journal = {Scientific Data},
  language = {en},
  number = {1}
}

@article{zhu2018,
  title = {A Lightweight Piecewise Linear Synthesis Method for Standard 12-Lead {{ECG}} Signals Based on Adaptive Region Segmentation},
  author = {Zhu, Huaiyu and Pan, Yun and Cheng, Kwang-Ting and Huan, Ruohong},
  editor = {Zhao, Jichao},
  year = {2018},
  month = oct,
  volume = {13},
  pages = {e0206170},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0206170},
  file = {/home/moritz/Documents/thesis.git/papers/zhu2018.pdf},
  journal = {PLOS ONE},
  language = {en},
  number = {10}
}

@article{zifan2006,
  title = {Automated {{Segmentation}} of {{ECG Signals}} Using {{Piecewise Derivative Dynamic Time Warping}}},
  author = {Zifan, Ali and Moradi, Mohammad Hassan and Saberi, Sohrab and Towhidkhah, Farzad},
  year = {2006},
  pages = {5},
  abstract = {Electrocardiogram (ECG) segmentation is necessary to help reduce the time consuming task of manually annotating ECG's. Several algorithms have been developed to segment the ECG automatically. We first review several of such methods, and then present a new single lead segmentation method based on Adaptive piecewise constant approximation (APCA) and Piecewise derivative dynamic time warping (PDDTW). The results are tested on the QT database. We compared our results to Laguna's two lead method. Our proposed approach has a comparable mean error, but yields a slightly higher standard deviation than Laguna's method.},
  file = {/home/moritz/Documents/thesis.git/papers/zifan2006.pdf},
  language = {en}
}

@misc{zotero-280,
  title = {A Fast Algorithm for Complex Discord Searches in Time Series: {{HOT SAX Time}}},
  shorttitle = {A Fast Algorithm for Complex Discord Searches in Time Series},
  url = {https://www.groundai.com/project/a-fast-algorithm-for-complex-discord-searches-in-time-series-hot-sax-time/1},
  urldate = {2021-03-30},
  abstract = {Time series analysis is quickly proceeding towards long and complex tasks. In recent years, fast approximate algorithms for discord search have been proposed in order to compensate for the increasing size of the time series. It is more interesting, however, to find quick exact solutions. In this research, we improved HOT SAX by exploiting two main ideas: the warm-up process, and the similarity between sequences close in time. The resulting algorithm, called HOT SAX Time (HST), has been validated with real and synthetic time series, and successfully compared with HOT SAX, RRA, SCAMP, and DADD. The complexity of a discord \ldots},
  file = {/home/moritz/Zotero/storage/5WGHTLIN/1.html},
  journal = {GroundAI},
  language = {en}
}

@misc{zotero-371,
  title = {Arrhythmia {{Essentials}} - 2nd {{Edition}}},
  url = {https://www.elsevier.com/books/arrhythmia-essentials/olshansky/978-0-323-39968-5},
  urldate = {2021-04-06},
  file = {/home/moritz/Zotero/storage/JJVGT2KA/978-0-323-39968-5.html}
}


